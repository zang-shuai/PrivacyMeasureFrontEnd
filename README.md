

# 面向隐私算法和发布数据的隐私保护水平度

**摘要**



**Abstract**



**目录**

[toc]



**注释表**

|      |      |      |      |
| ---- | ---- | ---- | ---- |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |
|      |      |      |      |

**缩略词**

|      |      |      |
| ---- | ---- | ---- |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |

## 绪论

### 研究背景及意义

在当今社会，大数据已成为推动经济、技术、社会进步的重要引擎。其应用覆盖金融、医疗、教育、交通等各行各业，赋予企业与机构更深入的洞察力。通过对大数据的分析和挖掘，组织可以更精准地了解用户需求，预测市场趋势，优化资源配置，从而提升效率和竞争力。同时，大数据在公共管理中也发挥着关键作用，帮助政府实现精准治理，如疫情防控、城市规划和环境监测等。在这个信息驱动的时代，大数据已然成为社会进步的重要基础，为决策制定和创新提供了坚实的支持。

然而，数据的广泛收集和高效分析为社会带来了便利，同时也显著提升了隐私泄漏的风险。随着各类设备和应用的普及，个人行为数据（如地理位置、购物记录、社交互动等）大量被采集，这些数据一旦被不当利用或泄露，可能会导致个人隐私遭受严重侵害。例如，未经授权的数据共享、网络攻击、以及内部数据滥用，都会导致用户敏感信息暴露。此外，数据挖掘和机器学习等技术的进步，使得隐私攻击变得更加隐蔽且难以防范。隐私泄漏不仅威胁个体的安全与信任感，还可能影响公共安全，导致信任危机。为此，隐私保护技术和数据治理政策的完善，已成为应对大数据时代隐私风险的关键措施。

为防止隐私泄漏，各企业和政府机构采取了多层次的措施，涵盖技术、制度和法律方面。首先，在技术层面，机构广泛应用数据加密、匿名化和差分隐私等技术，确保用户信息即使被访问或共享也难以识别具体个体。此外，企业和机构加强了对员工的隐私保护培训和内部权限管理，减少数据滥用的可能性。在制度层面，各组织建立了隐私保护的合规机制，严格遵循全球各地的隐私法规，如《通用的数据保护条例》（GDPR）和《加州消费者隐私法案》（CCPA）。这些法规要求企业在数据采集、存储和处理的每个环节进行透明化管理，增强用户对数据使用的控制权。这些技术与政策措施共同构建了多重保护机制，为用户隐私提供了更全面的保障。

当前，防止隐私泄露的主流方法主要包括差分隐私、数据匿名化、同态加密和联邦学习等技术。差分隐私通过在数据分析中加入随机噪声，使得外部攻击者难以推断出个体数据，确保用户隐私的数学安全性。数据匿名化则通过去除数据中的标识性信息，将个人身份与数据记录分离，以降低泄露风险。同态加密技术允许在加密状态下进行数据计算，使得数据在不解密的情况下即可完成处理，适用于高度敏感的数据环境。联邦学习通过在本地设备上训练模型并仅上传参数更新，避免了数据集中化存储带来的泄漏风险。这些方法在应对不同隐私泄露场景时各具优势，通过结合使用，能够有效提升数据隐私的整体防护水平。

为了确保隐私保护算法在设计和实现中的准确，对隐私算法的保护程度进行度量具有重要意义，这不仅影响着算法的科学性和适用性，也决定了其在实际应用中的安全性和用户信任度。随着隐私保护需求的提升，诸如本地差分隐私、数据匿名等算法逐步得到广泛应用，但这些算法在实际场景中的保护效果并不总是相同。因此，建立一套有效的度量方法来评估隐私保护程度，对验证和改进这些算法至关重要。

度量隐私保护算法的保护程度能够为技术选择提供客观依据。不同隐私保护算法在保护效果和计算开销上有所不同，度量标准可以帮助研发人员根据具体场景的需求，合理选择算法。例如，在高敏感性数据场景中，通过度量保护程度可以选择适合的算法，以达到最佳的隐私与性能平衡。

度量隐私保护程度是提升算法可信度和透明度的关键。在数据驱动的社会中，用户越来越关注隐私问题，而度量方法的建立可以直观地展示算法的保护效果，使用户更加信任这些技术。特别是在法律法规日益严格的情况下，有明确的隐私度量方法可以帮助企业满足合规要求，降低法律风险。通过有效的度量，企业和用户可以对隐私保护算法的效果有清晰认知，从而提升技术的可信度。

此外，度量隐私保护程度能够促进隐私保护技术的创新与改进。在科研和开发过程中，度量指标为研究人员提供了一个反馈机制，通过分析度量结果，算法设计者能够找到现有方法的不足之处并进行优化。比如，对于一个联邦学习框架，通过度量不同客户端上的数据嵌入泄露风险，研究人员可以更好地调优参数，提升系统整体的隐私保护性能。度量标准的建立将推动隐私保护技术向更高效、更精准的方向发展。

总之，度量隐私保护算法的保护程度，不仅有助于技术选择、提升可信度、满足合规要求，更能推动整个隐私保护领域的发展。通过科学的度量方法，我们能够更好地理解和优化隐私保护算法，从而为数据隐私安全提供可靠的技术支持。

因此，研究本地差分隐私在持续数据的隐私保护机制有重要的理论和现实意义。首先本文关注持续数据的聚合估计和真值发现场景，在用户发布数据流时，对数据进行实时的隐私保护，可以填补隐私保护领域的缺陷；同时，不仅仅在学术领域，本文考虑到实际的应用场景，推动了隐私保护领域中将理论用于实践的进展；最后，差分隐私领域中，平衡数据之间的隐私性和可用性是研究的核心问题，本文基于本地差分隐私提出了新的隐私保护模型，优化了传统的隐私预算分配方案来提高数据可用性。综上，本论文的研究为持续数据的采集提供了理论和实践支撑。

对隐私度量的研究有重要的理论和现实意义，首先本文对主流的隐私保护算法的度量进行了研究，不仅仅在学术领域，本文考虑到实际的应用，针对不同场景，提出了不同的度量方法，结合实际对算法进行优化，保证了在现实中的可用性与通用性。同时，对于常用的匿名模型也进行了隐私保护效果的评估，对于不同的匿名模型，本文给出了统一的度量方案，支持在熵减的情况下精确地计算出匿名化处理后数据集的隐私保护程度，同时保证了方法的通用性，使其能在更多场景下使用。

### 相关工作

#### 差分隐私算法的隐私度量

对于差分隐私算法的隐私度量，目前的研究大多数集中在中心化差分隐私模型下。

2013 年，Marco Gaboardi等人于[2013]中探讨了如何通过类型系统认证查询是否满足差分隐私性，并提出了名为DFuzz的扩展方法。文章指出，衡量差分隐私算法的核心在于敏感度度量，即查询结果在单条数据变动下的最大变化幅度。传统工具如Fuzz通过类型系统对敏感度进行静态分析，但无法处理敏感度依赖于运行时信息的场景。DFuzz在此基础上引入了线性索引类型和轻量级依赖类型，扩展了敏感度分析能力，能够度量并认证更多复杂算法的差分隐私性，包括那些依赖动态信息的迭代算法。

相对较近的方法是Benjamin Bichsel ETH Zurich等人在[]这篇文章提出的 DP-Finder 方法，该方法用于自动推导差分隐私算法的隐私保护下界。这个下界在差分隐私度量中具有重要意义，因为它可以验证现有上界的紧密性，甚至发现不正确的上界。文章指出，在差分隐私算法中，下界的计算涉及寻找隐私泄露最严重的反例（即两个相邻输入和一组输出），这是一个复杂的任务，因为需要在庞大且稀疏的搜索空间中查找。为解决这一挑战，DP-Finder提出了两大关键技术。首先，引入了精确的相关采样方法，以高效估计反例的隐私泄露程度。其次，将问题转化为可微优化问题，通过数值优化方法系统化地搜索隐私泄露较大的反例。这一创新使得下界的计算更为精准和高效。实验结果表明，DP-Finder能够有效计算多个随机化算法的差分隐私下界，尤其在输入具有复杂混淆机制的算法中表现突出。这一成果为差分隐私算法的度量提供了新的视角和工具，有助于评估隐私保护的实际强度，提升算法的可信度和准确性。

后来基于 DP-Finder 方法该团队在 2021 年又在[]中提出了DP-Sniper方法，一种改进的黑盒方法，用于自动发现差分隐私算法中的隐私泄露问题。作为DP-Finder的改进版，DP-Sniper专注于以更高效、更精准的方式度量差分隐私算法的隐私保护程度，其核心创新包括两个关键思想：一是训练分类器预测某个输出是否来自两个可能输入之一；二是将该分类器转化为近似最优的差分隐私攻击。这种方法将隐私泄露问题转化为分类任务，从而简化了分析过程。实验表明，DP-Sniper在度量差分隐私保护程度时，比 DP-Finder 提供了多达12.4倍更强的结果，同时计算速度快15.5倍。此外，DP-Sniper还能够有效检测算法中的浮点漏洞。例如，它发现一个声称满足0.1差分隐私的拉普拉斯机制实际上连0.25差分隐私都无法保证。这一改进显著提升了差分隐私算法度量的效率和精度，进一步验证了隐私保护算法在实际实现中的潜在问题，为隐私保护算法的优化和验证提供了更强大的工具支持。

最新的方法在 2022 年[]中被提出，该方法用于在完全黑盒环境下对差分隐私进行统计量化。研究重点在于通过估计和置信区间，量化随机化算法的最优隐私参数以及其他关键变量（如“数据中心隐私级别”）。与传统方法不同，这种新方法基于隐私的局部特性，并避免了“事件选择”这一复杂步骤，这是隐私验证中的主要障碍之一。因此，该方法实现简单，用户友好。文章通过理论分析证明了估计器的快速收敛性及置信区间的渐近有效性。在实验中，作者验证了多种算法的隐私参数，结果表明该方法在度量差分隐私算法保护程度时具有较高的效率和准确性。这种方法为差分隐私的度量提供了一种统计学上的新视角，使得隐私验证更加直观和实用，尤其在需要高效、可靠度量的实际应用场景中具有重要意义。

#### 匿名数据的隐私度量

数据匿名化（Data Anonymization）是一种经典的隐私保护技术，通过去除或模糊化能够识别个人身份的信息，使数据脱敏，进而降低隐私泄露的风险。这种方法广泛应用于医疗、金融等行业，尤其在大规模数据共享和开放数据集中的隐私保护中具备重要的地位。对于度量匿名数据的隐私保护程度，目前有了较为广泛的研究。

于 2009 年 G. Smith 等人在[]中研究了信息流量化理论在匿名协议、安全信息流和侧信道分析中的应用，并提出了一种基于Rényi’s min-entropy的新方法，用于改善当前量化信息流理论的隐私度量。传统量化信息流理论以香农熵（Shannon entropy）和互信息为基础，虽然能衡量隐私泄露，但在某些攻击威胁下，缺乏足够的安全保证。例如，即使随机变量具有较高的香农熵，其仍可能容易被攻击者猜中。文章针对单次攻击成功猜测秘密信息的威胁模型，指出传统基于香农熵的定义在此情境下并不可靠。为此，作者引入了一种新的度量方法，基于与贝叶斯风险密切相关的易受攻击性概念，采用Rényi’s min-entropy衡量不确定性。这种方法更准确地量化了攻击成功的可能性，为匿名数据隐私保护程度的度量提供了更强的理论保障。通过这一创新，文章为评估匿名机制中的隐私泄露提供了更实用的工具，能够有效反映攻击风险，提升现有隐私保护方法的精确性和安全性。

2019 年，这篇文章提出了一个全新的隐私度量指标——Discrimination Rate (DR)，用于量化匿名系统的隐私效率，特别是针对属性级别的识别能力进行精细化测量。DR 基于信息论构建，度量结果范围为 [0, 1]，可以反映匿名数据在保护属性隐私方面的强弱，同时也体现了攻击者识别特定属性的能力。相比传统指标，DR 更具细粒度，可量化单个属性对匿名集合的影响。文章详细讨论了定义这一指标所需的关键特性，并提供了便于实际应用的算法，使 DR 能够直接用于匿名系统的隐私保护评估。通过 DR 的测量，研究还引入了诸如sketchy-identifiers**、**zero-identifiers 和 partial-identifiers 等新概念，为属性识别的分类和理解提供了更准确的定义。为了验证 DR 的实用性，文章对 k-匿名性和 l-多样性两种常见匿名机制进行了评估和比较，展示了 DR 在实际数据集上的有效性。这项研究为匿名数据隐私保护程度的度量提供了一个创新方法，不仅能够量化攻击风险，还能为匿名系统的设计与优化提供科学依据。

在最近的一项工作中[]，作者根据[]中提出的相关方法，提出的更加详细的隐私度量方案。该文章研究了数据集中基于匿名化的隐私保护机制的有效性度量，提出了一种信息论度量方法——Sanitization Degree (η)，用于量化匿名化过程的隐私保护程度。Sanitization Degree 赋予匿名化过程一个累积评分，范围为 [0, 1]，值越接近1表示隐私保护越强。作者设计该指标的核心思想是，匿名化机制在减少数据库属性间关联信息的同时，还需尽可能保留数据的实用性。文章进一步分析了隐私与数据实用性之间的权衡，并通过建立这两者的关系模型，揭示了匿名化过程中的隐私-实用性平衡。为验证方法的实际效果，研究对三种常见的匿名化模型（k-匿名性、l-多样性和t-closeness）进行了实证分析，基于真实数据计算了 η 的值。这项工作为匿名化数据隐私保护程度的量化提供了一个系统化框架，有助于评价不同匿名化方法的有效性，并为优化隐私保护机制提供理论支持。

#### 相关工作小结

对于差分隐私算法的隐私度量，总体上可分为两大类，白盒度量与黑盒度量，白盒度量可在已知算法保护程度的情形下进行，黑盒度量主要集中于输入输出本身而非算法的具体内容。不过，目前的研究大多数集中在中心化差分隐私模型下，因此本文将集中于对本地差分隐私的度量，并对白盒度量与黑盒度量都有一定程度的研究。对于不同输入输出类型的本地差分隐私算法，都进行了一定程度的研究，保证了方法的通用性。

对于匿名数据的隐私度量，虽然已经有了较多参考文献，但是相关方案仍有一定的局限性，在[]中提出的方法，虽然取得了较好的成果，不过其度量结果忽略了处理前隐私信息与处理后隐私信息的变化。如果在对数据的隐私信息也进行了一定程度的处理，那么其隐私保护程度理论上应该更高，但在实际的度量结果中无法将该现象体现出来。在最近的一项工作 [] 中，其隐私保护程度的度量基于一个比较严苛的假设前提，该假设前提要求数据在进行匿名处理时，必须要对隐私列进行处理，导致了如果匿名方案中没有修改隐私属性，便无法使用该方案进行计算，有很大的局限性。本文基于这些论文的主要思想，同时解决了这些论文中为考虑到的相关情况，提出了更新的解决方法。

### 本文工作

本文工作主要是用于度量隐私算法对数据的隐私保护程度而展开。工作分为两个部分，第一部分主要集中于度量本地差分隐私算法的隐私保护程度，对于不同使用场景，提出了基于算法的度量方案。同样在实现的过程中，考虑到实际的实现硬件，也给出了相对通用的，使用 CPU 进行度量的方案，和基于 GPU 的高性能度量方案。第二部分主要集中于度量匿名数据的隐私保护程度，该度量主要是针对于中心化的数据，度量主要集中于对比数据发布前与发布后的差异。以此来量化隐私保护的具体程度。

（1）度量本地差分隐私算法的隐私保护程度

本文提出了一个系统化框架，用于评估本地差分隐私（Local Differential Privacy, LDP）算法的隐私保护效果，并基于此框架推导出算法的实际隐私预算值。为确保测试结果的科学性与严谨性，本文详细计算了测试误差范围，并分析了影响测试精度的主要因素，特别是测试次数的选择对统计建模的显著作用。

在框架设计过程中，由于LDP算法的隐私效果需通过多次运行进行统计建模，测试次数成为决定结果精确度的关键变量。为此，本文系统性地给出了测试范围与运行次数的选择方案，以在计算资源与测试精度之间实现平衡。同时，本文针对当前较为常用的本地差分隐私算法，进行了大规模的实验验证。通过多次重复测试并统计最终的实验结果，本文提供了一系列量化分析，为读者深入理解LDP算法的隐私保护性能提供了重要参考。此外，本文从算法的可观测性角度出发，探讨了两类隐私评估场景的适用性：白盒测试和黑盒测试。在白盒场景中，假设评估者已知算法的设计细节和保护机制，可直接分析算法内部工作逻辑并进行针对性测试；而在黑盒场景中，评估者无法获取算法的内部实现细节，仅能通过算法的输入与输出关系进行隐私保护性能的评估。本文提出的度量方法适用于上述两种场景，尤其在黑盒测试中，通过输入输出的统计分析实现对隐私预算的有效估计。

（2）度量匿名数据的隐私保护程度

该部分的研究重点是基于现有工作的启发，开发出一种通用且精确的衡量标准，用于量化匿名化处理后数据集的隐私保护水平。通过引入信息论的相关方法，本文旨在比较数据集在匿名化处理前后的信息差异，并进一步结合加权策略以综合评估数据集的整体隐私保护程度。

具体而言，本文首先对匿名化处理前后数据集中的各种属性进行分类，并为不同类别的属性设定明确的标记规则。随后，定义了一个关键指标——PL（Privacy Level），用于量化数据隐私保护水平。PL的核心思想在于，通过计算从准标识符信息中推导隐私数据的难度，以及在数据经过匿名化处理后，基于残余信息推测原始隐私数据的难度。最终计算所得的难度值被视为隐私保护水平的量化结果，难度值越高，则表明数据的隐私保护程度越高。此外，本文提出的PL指标支持对数据集中不同属性的隐私保护水平进行单独评估。通过将数据集中各个属性分别代入PL模型，可以得到针对每个属性的隐私保护水平评估值；进一步通过加权策略对不同属性的评估值进行整合，得出数据集整体的隐私保护水平。这种方法不仅能够揭示数据集内各属性间的隐私保护差异，还为数据管理者在数据发布前进行全面隐私评估提供了量化依据。

### 论文结构

本文各章节的组织架构具体如下： 

第一章作为绪论部分，引入了隐私度量的研究背景，通过对相关工作和研究现状的分析，总结概括了本文的主要工作和论文的组织架构。

第二章介绍了与本文工作相关的基础知识，包括中心化差分隐私和本地差分隐私，以及常用的数据匿名模型，本文后续的实验将会在该模型上使用。

第三章首先分析了本地差分隐私算法在频率估计和均值估计上的度量方式，并针对不同的使用场景，提出了黑盒度量方法和白盒度量方法，并通过理论对隐私性、可用性等进行了分析，最后通过实验评估了所提框架的效用。

第四章介绍了本文的第二项工作，首先提出匿名数据的隐私度量模型，其次根据一个微型数据集，对常用的匿名模型进行了度量，从而详细说明度量原理，并通过理论和实验对所提算法进一步对比和评估。

第五章总结了本文工作，指出本文工作的不足之处，并展望了未来进一步研究方向。

## 基础知识

### 差分隐私

差分隐私（Differential Privacy）是一种保护数据隐私的数学框架，旨在在数据分析和共享过程中有效防止个体信息泄露。其核心思想是通过在查询结果中注入随机噪声，确保攻击者无法从两个仅相差一条记录的数据集中推断出该记录的具体信息。差分隐私的强度由隐私预算 $\epsilon$ 控制： $\epsilon$ 值越小，隐私保护越强，但数据的可用性可能降低；反之，较大的 $\epsilon$ 提供更高的数据实用性但隐私保护较弱。

差分隐私分为两类：中心化差分隐私和本地差分隐私。前者依赖于可信数据中心发布聚合统计信息，后者则允许用户在数据发布前通过本地处理实现隐私保护。差分隐私被广泛应用于统计分析、机器学习和隐私保护计算等领域，为数据共享与隐私保护提供了理论保障。

#### 中心化差分隐私

给定两个数据集 $D$ 和 $D ^ { \prime } $, 两个数据集最多差一条记录，则称为相邻数据集。中心化差分隐私的定义如下： 

定义2.1（ $\epsilon$-差分隐私）给定一个隐私保护算法及 $\mathrm{A}$ 定义域 $\operatorname { Dom } ( \mathrm{A} )$ 和值域 $\operatorname { Ran } ( \mathrm{A} ) $, 对于任意两个相邻数据集 $D$ 和 $D ^ { \prime }$ 和 任意输出 $y ^ { * } \left( y ^ { * } \subseteq \operatorname { Ran } ( \mathrm{A} ) \right) ,$ 如果算法 $\mathrm{A}$ 满足公式(2.1)， 则满足 $\epsilon$-差分隐私。 

$$
\operatorname { Pr } \left[ \mathrm{A} ( D ) = y ^ { * } \right] \leq e ^ { \epsilon } \cdot \operatorname {Pr}\left[ \mathrm{A} \left( D ^ { \prime } \right) = y ^ { * } \right]
$$

其中，根据实际场景，隐私预算的取值设置各不相同，最终目的都是为了保证数据隐私性和可用性的平衡。 

差分隐私的核心思想是在数据发布过程中添加噪声，以防止隐私信息被泄露。为了确保数据的隐私性，需要根据敏感度来确定噪声的规模。敏感度是指在数据集中某一记录的变化对查询结果的最大影响程度，敏感度分为全局敏感度和局部敏感度。 

定义2.2（全局敏感度）对于任意一个函数 $f : D \rightarrow R ^ { d } ,$ 全局敏感度定义为： 
$$
\Delta f = \max _ { D , D ^ { \prime } } \| f ( D ) - f \left( D ^ { \prime } \right) \|
$$

其中， $R$ 表示映射的实数空间， $d$ 表示查询维度， $D$ 和 $D ^ { \prime }$ 是相邻数据集。 

定义2.3（局部敏感度）对于任意一个函数 $f : D \rightarrow R ^ { d } ,$ 局部敏感度定义为： 
$$
\Delta f = \max _ { D } \| f ( D ) - f \left( D ^ { \prime } \right) \|
$$
全局敏感度和局部敏感度最大的区别是是否考虑数据的分布情况，全局敏感度不考虑数据的分布，可能会因为数据加的噪声过大影响可用性。 

<img src="/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20241114164245064.png" alt="image-20241114164245064" style="zoom:50%;" />

#### 本地差分隐私


定义2.4（本地差分隐私）算法 $\mathrm{A}$ 满足 $\epsilon$-本地差分隐私（$\epsilon$-LDP），其中 $\epsilon \geq 0$，当且仅当对于任意输入 $v$ 和 $v'$，都有
$$
\operatorname{Pr}\left[\mathrm{A}\left(v\right)=y\right] \leq e^{\epsilon} \operatorname{Pr}\left[\mathrm{A}\left(v^{\prime}\right)=y\right]
$$
其中，$v$ 和 $v^{\prime}$ 是用户的两个不同输入，$y$ 是算法 $\mathrm{A}$ 的输出。如果算法 $\mathrm{A}$ 满足公式 1 的条件，则可以认为其满足 $\epsilon$-LDP。

<img src="/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20241114164306068.png" alt="image-20241114164306068" style="zoom:50%;" />

### 数据匿名

#### k-anonymity<1>

k-匿名（k-Anonymity）是一种用于保护数据隐私的经典技术，通过对数据集中的敏感信息进行结构化处理，减少个体隐私泄露的风险。其核心思想是确保每个记录在数据集中与至少 k-1 条其他记录在某些准标识符（quasi-identifiers）属性上无法区分，从而隐匿个体在群体中的存在。

例：

table1:

![image-20220714150528526](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20220714150528526.png)

table2:

![image-20220714150545864](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20220714150545864.png)

table2满足 $3-anonymity$，准标识符 $QI= \{ZIPCode, Age\}$。Disease是敏感数据.

k-anonymity能保证，攻击者无法知道某个人是否在公开的数据中。给定一个人，攻击者无法确认他是否有某项敏感属性。同样攻击者无法确认某条数据对应的是哪个人（这条假设攻击者除了准标识符信息之外对其他数据一无所知，举个例子，如果所有用户的偏好都是购买电子产品，那么 k-anonymity 也无法保证隐私没有泄露）

k-匿名算法存在着一些攻击方式： 

- 同质化攻击：某个k-匿名组内对应的敏感属性的值也完全相同，这使得攻击者可以轻易获取想要的信息。 
- 背景知识攻击：即使k-匿名组内的敏感属性值并不相同，攻击者也有可能依据其已有的背景知识以高概率获取到其隐私信息。
- 未排序匹配攻击：当公开的数据记录和原始记录的顺序一样的时候，攻击者可以猜出匿名化的记录是属于谁。例如如果攻击者知道在数据中小明是排在小白前面，那么他就可以确认，小明的购买偏好是电子产品，小白是家用电器。解决方法也很简单，在公开数据之前先打乱原始数据的顺序就可以避免这类的攻击。
- 补充数据攻击：假如公开的数据有多种类型，如果它们的k-anonymity方法不同，那么攻击者可以通过关联多种数据推测用户信息。

#### l-diversity<1>

如果一个等价类里的敏感属性至少有1个良表示 (well-represented) 的取值，则称该等价类具有 $l-diversity$。如果一个数据表里的所有等价类都具有 $l-diversity$，则称该表具有 $l-diversity$。

良表示：

1. 可区分良表示：最简单的 $l-diversity$ 要求同一等价类中的敏感属性要有至少有 $l$ 个可区分的取值。但是，如果某一个取值的频率明显高于其他取值，这将使得观察者可以以较高的置信度认为这一等价类中的敏感属性都取这个值。这导致了下面两种良表示定义。

2. 熵良表示：记S为敏感属性的取值集合，$p(E,s)$ 为等价类$E$中敏感属性取值$s$的概率，熵 $l-diversity$ 要求下式成立：
$$
\operatorname{Entropy}(E)=-\sum_{s \in S} p(E, s) \log_2 p(E, s) \geq \log_2 l
$$
若每一等价类都满足熵 $l-diversity$，那么整张数据表的熵也必然不小于 $\log_2 l$。这个要求太严格了，比如敏感属性的取值集合中某些取值的频率较高，这将导致整张表的熵比较低。

3. 递归良表示：确保最频繁的值不会出现得太频繁，而频率较低的值不会出现得太少。设 $m$ 是等价类 $E$ 中的值的数目，和 $r_i$：$1 \leq i \leq m$ 是第 $i$ 繁的敏感值在等价类 $E$ 中出现的次数。若等价类E满足$(c, \ell)-diversity$ 则 $r_{1}<c\left(r_{l}+r_{l+1}+\ldots+r_{m}\right)$

例：

![image-20220707155322761](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20220707155322761.png)



![image-20220707155333733](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20220707155333733.png)

#### t-closeness<1>

$t-closeness$ 认为，在数据表公开前，观察者有对于客户敏感属性的先验信念 (prior belief），数据表公开后观察者获得了后验信念 (posterior belief)。这二者之间的差别就是观察者获得的信息 (information gain) $t-closeness$将信息获得又分为两部分：关于整体的和关于特定个体的。

记观察者的先验信念为$B_0$，我们先发布一个抹去准标识符信息的数据表，这个表中敏感属性的分布记为 $Q$，根据 $Q$，观察者得到了 $B_1$；然后发布含有淮标识符信息的数据表，那么观察者可以由准标识符识别特定个体所在等价类，并可以得到该等价类中敏感属性的分布 $P$，根据 $P$，观察者得到了 $B_2$。

$l-diversity$ 其实就是限制 $B_2$ 与 $B_0$ 之间的区别。然而，我们发布数据是因为数据有价值，这个价值就是数据整体的分布规律，可以用 $B_0$ 与 $B_1$ 之间的差别表示。二者差别越大，表明数据的价值越大，这一部分不应被限制。也即整体的分布 $Q$ 应该被公开。因为这正是数据的价值所在。而 $B$ 与 $B$ 之间的差别，就是我们需要保护的隐私信息，应该被尽可能限制。

$t-closeness$ 通过限制 $P$ 与 $Q$ 的距离来限制 $B_1$ 与 $B_2$ 的区别。其认为如果 $P=Q$，那么应有 $B_1= B_2$。$P$、$Q$越近，$B_1$、$B_2$也应越近。 

The t-closeness Principle：如果等价类 $E$ 中的敏感属性取值分布与整张表中该敏感属性的分布的距离不超过阈值t，则称 $E$ 满足 $t-closeness$。如果数据表中所有等价类都满足 $t-closeness$，则称该表满足 $t-closeness$。

![image-20220707155414220](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20220707155414220.png)



### 本章小结

本章的第一节与第二节分别探讨了差分隐私（Differential Privacy, DP）和数据匿名技术，这两种数据保护方法在隐私保护领域中扮演了重要角色。第一节介绍了差分隐私中两大类：中心化差分隐私和本地差分隐私的概念、性质和经典方法，并比较了两者隐私保护模型的不同之处。然后介绍了数据匿名技术，回顾了几种经典的数据匿名方法，如 $k$-匿名、$l$-多样性和 $t$-接近性。这些技术通过隐藏个体的细节来保护隐私，同时在一定程度上保留了数据的统计价值。后文将详细介绍如何度量这些算法或数据的隐私保护程度。

## 隐私算法的度量（28）

### 引言

随着互联网技术的快速发展，网络平台已经成为人们日常生活中不可或缺的一部分。个人用户在网络上的行为活动产生了海量的数据，这些数据包括了用户的个人信息、购物记录、社交行为等多个方面。数据分析师通过挖掘和分析这些数据，可以洞察用户行为，预测市场趋势，从而帮助决策者制定更有效的商业策略或政策。数据中的频率、均值等统计信息，对于分析个人喜好、预测未来数据走势至关重要。然而，这些数据的收集和分析往往涉及到敏感个人信息，如何在保护用户隐私的同时，有效利用数据资源，已经成为一个亟需解决的问题。

在数据隐私保护领域，本地差分隐私（Local Differential Privacy, LDP）作为一种新兴的隐私保护技术，已被越来越多的科技企业和研究机构所采纳。LDP的核心思想是在数据在离开用户设备前就进行隐私保护处理，即用户不直接向服务器发送原始数据，而是发送经过随机化处理的数据。这种处理保证了数据的隐私性，即使收集数据的后台服务也无法确切知晓个体用户的真实数据。

在LDP的实现中，隐私保护程度由参数 $\epsilon$（epsilon） 控制，通常称为隐私预算。$\epsilon$ 值的大小直接影响到隐私保护的强度：$\epsilon$ 值越小，隐私保护级别越高，但同时数据的实用性可能降低；反之，$\epsilon$ 值较大时，虽然数据的实用性提高，但隐私保护的效力则减弱。在实际应用中，选择合适的 $\epsilon$ 值，平衡隐私保护和数据实用性，是设计LDP系统的一个重要挑战。

鉴于LDP技术的复杂性和对隐私保护程度的严格要求，开发一个能够准确检测LDP算法执行情况的度量框架显得尤为重要。该框架的目标是验证LDP算法的实际隐私保护效力是否符合设计预期，以及算法的实现是否正确无误。此框架需要具备高度的灵活性和广泛的适用性，以适应不同的算法检测需求，包括但不限于算法开发者内部测试和第三方独立审核。

为了实现这一目标，度量框架设计包括以下几个关键组成部分：

​	1.	**数据收集模块**：负责收集算法处理前后的数据，包括用户原始数据和经过LDP处理后的数据。

​	2.	**算法执行模块**：实现或调用特定的LDP算法，确保算法按预定的隐私参数 $\epsilon$ 执行。

​	3.	**隐私保护效力评估模块**：通过对比算法输出和理论模型，评估实际隐私保护程度与预期是否一致。

​	4.	**数据实用性分析模块**：评估经过隐私保护处理的数据的实用性，包括数据的准确性、偏差分析等统计指标。

​	5.	**安全性测试模块**：检测潜在的数据泄露风险和算法实现中的安全缺陷。

通过上述模块的综合运作，度量框架能够全面评估LDP算法从设计到部署的各个方面。此外，框架的设计允许适应性强、可扩展，能够对不同类型的LDP算法进行有效的适应和测试。

总之，随着数据隐私保护要求的提高和数据利用需求的增加，开发和部署有效的隐私保护技术显得尤为重要。本文提出的度量框架为LDP算法的正确实施提供了强有力的工具，有助于实现在保护用户隐私的同时最大化数据的价值。

### 统计学基础

#### 矩估计

矩估计是一种常用的参数估计方法，通过样本矩的性质来估计总体参数的值。在矩估计中，我们使用样本矩和总体矩之间的关系来得到参数的估计值。

设 $X$ 为连续型随机变量，其概率密度为 $f\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right)$, 或 $X$ 为离散型随机变量, 其分布律为 $P\{X=x\}=p\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right)$，其中 $\theta_{1}, \theta_{2}, \cdots, \theta_{k}$ 为待估参数， $X_{1}, X_{2}, \cdots, X_{n}$ 是来自 $X$ 的样本. 假设总体 $X$ 的前 $k$ 阶矩
$$
\mu_{l}=E\left(X^{l}\right)=\int_{-\infty}^{\infty} x^{l} f\left(x ; \theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) \mathrm{d} x \quad(X \text { 连续型 })\\
l=1,2, \cdots, k
$$

（其中 $R_{X}$ 是 $X$ 可能取值的范围）存在。 一般来说, 它们是 $\theta_{1}, \theta_{2}, \cdots, \theta_{k}$ 的函数. 基于样本矩

$$
A_{l}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{l}
$$

依概率收敛于相应的总体矩 $\mu_{l}(l=1,2, \cdots, k)$ ，样本矩的连续函数依概率收敛于相应的总体矩的连续函数，我们就用样本矩作为相应的总体矩的估计量，而以样本矩的连续函数作为相应的总体矩的连续函数的估计量。这种估计方法称为矩估计法. 矩估计法的具体做法如下: 设

$$
\left\{\begin{aligned} \mu_{1} & =\mu_{1}\left(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\right), \\ \mu_{2} & =\mu_{2}\left(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\right), \\ & \vdots \\ \mu_{k} & =\mu_{k}\left(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\right) .\end{aligned}\right.
$$
这是一个包含 $k$ 个未知参数 $\theta_{1}, \theta_{2}, \cdots, \theta_{k}$ 的联立方程组. 一般来说，可以从中解出 $\theta_{1}, \theta_{2}, \cdots, \theta_{k}$，得到
$$
\left\{\begin{aligned} \theta_{1} & =\theta_{1}\left(\mu_{1}, \mu_{2}, \cdots, \mu_{k}\right), \\ \theta_{2} & =\theta_{2}\left(\mu_{1}, \mu_{2}, \cdots, \mu_{k}\right), \\ & \vdots \\ \theta_{k} & =\theta_{k}\left(\mu_{1}, \mu_{2}, \cdots, \mu_{k}\right) .\end{aligned}\right.
$$
以 $A_{i}$ 分别代替上式中的 $\mu_{i}, i=1,2, \cdots, k$，就以
$$
\hat{\theta}_{i}=\theta_{i}\left(A_{1}, A_{2}, \cdots, A_{k}\right), i=1,2, \cdots, k
$$
分别作为 $\theta_{i}, i=1,2, \cdots, k$ 的估计量，这种估计量称为矩估计量。矩估计量的观察值称为矩估计值。

#### 核密度估计

 与参数估计不同，非参数估计并不加入任何先验知识，而是根据数据本身的特点、性质来拟合分布，这样能比参数估计方法得出更好的模型。核密度估计就是非参数估计中的一种。有些本地差分隐私算法，输出值是连续值，此时难以直接进行统计，便使用核密度估计法进行统计。

在数据集为连续值时，要观察这些样本的分布情况，往往会采用直方图的方法来进行直观的观测。但直方图法求出的密度函数是不平滑的，密度函数受子区间宽度影响很大，同样的数据如果取不同的子区间范围，那么展示的结果可能有很大的差别。

除此之外，直方图还存在一个问题，那就是直方图展示的分布曲线并不平滑，即在一个子区间中的样本具有相等的概率密度，显然，这一点往往并不正确。解决这一问题的办法时增加子区间的数量，当子区间增加到样本的最大值时，就能对样本的每一点都会有一个属于自己的概率，但同时会带来其他问题，样本中没出现的值的概率为0，概率密度函数仍然不连续。如果我们将这些不连续的区间连续起来，那么这很大程度上便能符合我们的要求，其中一个思想就是对于样本中的某一点的概率密度，如果能把邻域的信息利用起来，那么最后的概率密度就会很大程度上改善不连续的问题。

首先，如果我们想知道 $x$ 处的密度函数值，可以像直方图一样，选一个 $x$ 附近的区间，数一下在这个区间里面的点的个数，除以总个数，密度函数可以写为：

$$
f(x)=\lim \limits_{h \rightarrow 0} \frac{F(x+h)-F(x-h)}{2 h}
$$
如果计算 $x$ 处的密度函数值，根据上面的思想，取 $x$ 的邻域 $[x-h,x+h]$，当 $h \rightarrow 0$ 的时候，便能把该邻域的密度函数值当作 $x$ 点的密度函数值：
$$
\hat{f}(x)=\frac{1}{2 h} \lim \limits_{h \rightarrow 0} \frac{N_{x_i \in[x-h, x+h]}}{n}
$$
$N_{x_i \in[x-h, x+h]}$ 是该邻域中的样本点数量，$n$ 样本集的总数量，最后对该邻域内的密度值取平均便得到 $x$ 点的密度函数值 $f(x)$。把上面的式子进行改写，即：核密度估计（Kernel density estimation），是一种用于估计概率密度函数的非参数方法，为独立同分布 $F$ 的 $n$ 个样本点，设其概率密度函数为 $f$：
$$
\hat{f}(x)=\frac{1}{2n h } \sum_{i=x-h}^{x+h} x_{i}=\frac{1}{nh} \sum_{i=1}^{N}  \frac{\left|x-x_{i}\right|}{2 h}<1, h\rightarrow 0
$$

这里 $h$ 如果选的太大，肯定不符合 $h$ 趋向于 0 的要求。$h$ 选的太小，那么用于估计 $f(x)$ 的点实际上非常少。这也就是非参数估计里面的 bias-variance tradeoff，也就是偏差和方差的平衡。这样后还是存在一个问题，那就是概率密度函数依然不够平滑，因为两个数之间的存在无数个数。

为此，便引入核函数的概念，用平滑的核函数 ${K}({t})$ 代替 $ {\left|x-x_{i}\right|}/{2 h}$ 。

选取的核密度必须满足三条性质:

1. 非负性: $K(x) \geq 0, x \in R$;
2. 对称性: $K(x)=K(-x), x \in R$;
3. 归一性: 即 $K(x)$ 在区间 $[-\infty,+\infty]$ 上的积分为 $1$ ， $ \int_{-\infty}^{+\infty} K(x) d x=1$ 。

由于高斯内核方便的数学性质，本实验使用高斯核函数： $K(x)= ϕ(x)$，$ϕ(x)$ 为标准正态概率密度函数。 

因此可以写为：
$$
\hat{f}(x)=\frac{1}{nh} \sum_{i=1}^{N}  K\left(\frac{\left|x-x_{i}\right|}{h}\right)
$$

#### KL散度与JS散度

KL散度又称为相对熵，如果我们对于同一个随机变量 $x$ 有两个单独的概率分布 $P_1(x)$ 和 $P_2(x)$，我们可以使用 KL 散度（Kullback-Leibler (KL) divergence）来衡量这两个分布的差异。

在本文中，我们将计算两个变量间的分布差异，两个变量间的分布分别用 $P_1$ 和 $P_2$ 表示，那么KL散度就可以计算两个分布的差异：
$$
K L(P_1 \| P_2)=\sum p_1(x) \log \frac{p_1(x)}{p_2(x)}
$$
从KL散度公式中可以看到 $P_1$ 的分布越接近 $P_2$（ $P_2$ 分布越拟合 $P_1$ ），那么散度值越小，即差异越小。

因为对数函数是凸函数，所以KL散度的值为非负数。

有时会将KL散度称为KL距离，但它并不满足距离的性质：

1. KL散度不是对称的；
2. KL散度不满足三角不等式。

**JS散度**度量了两个概率分布的相似度，基于KL散度的变体，解决了KL散度非对称的问题。一般地，JS散度是对称的，其取值是0到1之间。定义如下：
$$
J S\left(P_{1}, P_{2}\right)=\frac{1}{2} K L\left(P_{1} \| M\right)+\frac{1}{2} K L\left(P_{2} \| M\right)
$$
其中， $M = \frac{P_{1} + P_{2}}{2}$ 。

由于JS散度具有对称性，因此在本文中主要以JS散度来进行衡量。

### 基于算法的隐私度量

本节中，我们介绍了当已知本地差分隐私（LDP）算法的操作原理时，如何衡量隐私保护级别。

为了满足隐私预算，本地差分隐私算法需要适当地扰动数据。为了使收集者能够计算准确的统计结果，数据必须遵循一致的扰动规则。因此，在进行扰动之前，数据需要标准化，我们称这个过程为“编码”。只有经过编码之后，数据才能被扰动。

一个本地差分隐私算法 $A$ 的具体过程可以分为三步：

- 根据算法的编码规则，将原始数据集 $V$ 映射到一个新的集合 $X$，即 $x = \operatorname{Encode}_\mathrm{A}(v)$。
- 以概率 $p$ 扰动编码后的值 $x$，并将扰动后的值提交给收集者，即 $y = \operatorname{Perturb}_\mathrm{A}(x)$。
- 收集者再汇总这些扰动后的值，以推断出真实的概率分布。

对于频率估计机制，原始数据由离散值组成，数据收集的主要目的是统计各种元素的分布。即使原始数据是数值类型，在统计分析中也不考虑其大小。因此，编码过程主要涉及将原始输入集合映射到一个新的离散集合。扰动过程涉及选择输出正确编码数据还是其他伪造数据。输出正确数据的概率越低，隐私保护的级别就越高。

对于均值估计机制，原始数据是数值型的，统计结果不是频率分布，而是数据的均值。因此，编码过程不能忽略数据的大小。在大多数情况下，编码将数据映射到一个有限范围内，例如 $[-1, 1]$。理论上，隐私保护级别越高，扰动的范围就越大。

然而，并非所有的 LDP 算法都存在严格的编码过程。例如，在频率估计的随机响应机制中，原始数据会直接被扰动而无需编码。在这种情况下，编码结果被视为与原始值相同。

本文使用的符号约定如下：

| 符号         | 描述                          |
| ------------ | ----------------------------- |
| $\mathrm{A}$ | 待测量的 LDP 算法             |
| $V$          | $\mathrm{A}$ 的所有输入值集合 |
| $k$          | 集合 $V$ 的大小               |
| $v$          | $\mathrm{A}$ 的一个输入值     |
| $X$          | $\mathrm{A}$ 的编码值集合     |
| $x$          | $\mathrm{A}$ 的编码值         |
| $y$          | $\mathrm{A}$ 的扰动值         |
| $n$          | 测试运行次数                  |

表 1. 符号与描述

#### 频率估计机制的测量

LDP 算法的保护级别测量在于评估编码值 $x$ 与扰动值 $y$ 之间的差异。

该过程可以分为五个步骤：

1. 从列表 $\mathcal{V}_d$ 中随机选择 $n$ 个数字作为测试输入。
2. 对 $\mathcal{V}_d$ 中的值进行编码，生成 $\mathcal{X}$。
3. 对 $\mathcal{X}$ 中的值进行扰动，生成 $\mathcal{Y}$。
4. 比较 $\mathcal{X}$ 和 $\mathcal{Y}$ 之间的差异，生成新的列表 $\mathcal{D}$。
5. 将列表 $\mathcal{D}$ 代入测量公式，确定算法的保护级别。

```plaintext
算法1：频率估计机制的测量
输入：$\mathcal{V}_d=\{v_1,v_2, \cdots, v_n\}$
输出：测量结果 $\hat{\epsilon}$
1. 函数 ABMeasure($\mathcal{V}_d$)
2. 生成 $\mathcal{X} := (x_1, \cdots, x_n)$，其中 $x_i \sim \operatorname{Encode}_{\mathrm{A}}(v_i)$
3. 生成 $\mathcal{Y} := (y_1, \cdots, y_n)$，其中 $y_i \sim \operatorname{Perturb}_{\mathrm{A}}(x_i)$
4. 生成 $\mathcal{D} := (d_1, \cdots, d_n)$，其中 $d_i \sim \operatorname{Different}_{\mathrm{A}}(x_i,y_i)$
5. 设置 $\hat{\epsilon} := \operatorname{Measure}_{\mathrm{A}}(\mathcal{D})$
6. 返回 $\hat{\epsilon}$
```

函数 $\operatorname{Different}_\mathrm{A}(x,y)$ 和 $\operatorname{Measure}_\mathrm{A}(\mathcal{D})$ 需要针对不同的 LDP 算法进行具体设计。

函数 $\operatorname{Different}_\mathrm{A}(x,y)$ 用于比较编码值 $x$ 和扰动值 $y$ 之间的差异，并生成列表 $\mathcal{D}$。而函数 $\operatorname{Measure}_\mathrm{A}(\mathcal{D})$ 则根据算法的特性和扰动前后的差异，来确定算法的扰动结果。由于不同的算法具有不同的编码和扰动机制，因此需要对值的计算进行调整。

**示例 1**：直接编码（DE）。它是随机响应技术的推广，即输入域和输出域是相同的。当输入域大小为 $k$ 时，用户的输入 $v$ 以概率 $p$ 保留，即输出仍为 $v$。以概率 $1-p$，输入被扰动为输入域中的其他值，输出集合中输出任意值（非 $v$）的概率为 $q$。

**编码**： 

$$
x=\operatorname{Encode}_{\mathrm{DE}}(v)=v
$$

**扰动**：$ y=\operatorname{Perturb}_{\mathrm{DE}}(x)$

$$
\operatorname{Pr}\left[y=i\right]=\left\{\begin{array}{ll}p=\frac{e^{\varepsilon}}{e^{\varepsilon}+k-1}, & \text { 如果 } i=x \\ q=\frac{1}{e^{\varepsilon}+k-1}, & \text { 如果 } i \neq x\end{array}\right.
$$

为了测量隐私预算，有必要比较扰动值和编码值之间的差异，并计算它们的不同概率 $q$。隐私预算 $\epsilon$ 是基于 $q$ 计算的。算法 2 的函数 $\operatorname{Different}_{\operatorname{DE}}()$ 描述了比较过程的伪代码。

```plaintext
算法2：直接编码的不同函数
输入：$x$,$y$
输出：差异
1. 函数 Different\_DE($x$,$y$)
2. 如果 $x_i = y_i$
3. 返回 $1$
4. 否则
5. 返回 $0$
```

在算法 2 之后，我们将得到一个列表 $\operatorname{D}_{\operatorname{DE}}=\{d_1,d_2,...,d_i,...,d_n\}$。然后可以通过 $\operatorname{Measure}_{\operatorname{DE}}(\operatorname{D}_{\operatorname{DE}})$ 函数来获得隐私预算：

$$
\hat{\epsilon} = \mathrm{In}\left(\frac{n(k-1)}{\sum_n^i{d_i}}-k+1\right)
$$

#### 均值估计机制的测量

均值估计的输入值是数值数据，扰动可以概括为向原始数据添加均值为 0 的噪声。这导致均值估计机制的返回值与编码值相同的概率几乎为 0。噪声需要满足一定的分布规则，以确保后端能够正确计算均值。可以根据噪声的分布规则来确定隐私保护的程度。

与频率估计机制不同的是，无论输入值是什么，频率估计机制中的扰动值分布仅与隐私预算相关，而与输入值无关。但是在均值估计机制中，扰动不仅与隐私预算相关，还与编码值相关。这导致不同的编码值在扰动函数中的参数不同，从而输出不同的分布。

在 Duchi 机制中，扰动的相关概率 $p$ 和 $q$ 同时与编码值 $x$ 和隐私预算 $\epsilon$ 相关。在分段机制的扰动函数中，$l$ 和 $r$ 也与编码值相关。

因此，有两种计算隐私预算的方法：一种是找到与编码值无关但与隐私预算相关的参数，如 通用的数据发布算法评估 机制中的 $x'$ 和分段机制中的 $C$。通过这些参数，可以计算隐私预算。然而，这种方法假设算法设计没有错误，应用范围非常狭窄。另一种方法是固定编码值，获取相同编码值下的输出分布，然后根据分布推导出隐私预算。为了减少误差，可以从输入域中随机选择多个值，并通过多个隐私预算值的平均值来获得更准确的结果。本文主要采用第二种方法。

该过程可以分为四个步骤：

1. 从原始输入集 $V$ 中选择 $k$ 个值，形成输入集 $\mathcal{V}_c$。
2. 对 $\mathcal{V}_c$ 中的值进行编码，得到 $\mathcal{X}_c$。
3. 然后对集合 $\mathcal{X}_c$ 中的每个值进行扰动 $n$ 次，得到 $k$ 个输出集 $\mathcal{Y}_c^i$，其中 $i \in \{1,2,...,k\}$。
4. 统计数据集 $\mathcal{Y}_i$，计算这些值的大小，并计算隐私预算。

```plaintext
算法3：均值估计机制的测量
输入：$\mathcal{V}_d=\{v_1,v_2, \cdots, v_n\}$
输出：测量结果 $\hat{\epsilon}$
1. 函数 ABMeasure\_mean($\mathcal{V}_d$)
2. 生成 $\mathcal{V}_c=\{v_1,v_2,...,v_k\}$，其中 $\mathcal{V}_c \subseteq V$
3. 生成 $\mathcal{X}_c=\{x_1,x_2,...,x_n\}$，其中 $x_i \sim \operatorname{Encode}_{\mathrm{A}}(v_i)$
4. 对于 $i=1,2,\ldots,k$
5. 生成 $\mathcal{Y}_c^i=\{y_1,y_2,...,y_n\}$，其中 $x_i \sim \operatorname{Perturb}_{\mathrm{A}}(x_i)$
6. 设置 $\hat{\epsilon}_i = \operatorname{Measure}_{\mathrm{A}}(x',\mathcal{Y}_c^i)$
7. 返回 $\sup{\hat{\epsilon}_i}$
```

**示例 2**：通用的数据发布算法评估 机制。

Duchi 和他的同事们在其框架内提出了针对本地差分隐私的优化均值估计方案。在他们的模型中，假设用户的数据 $v$ 落在区间 $[a,b]$ 之内。首先，通过归一化将这些数据映射到 $[-1,1]$，如下所示：$x=\frac{2\cdot v'}{b-a}+\frac{a+b}{a-b}$，其中 $x$ 表示映射后的值。根据用户的实际数据 $v$，该方案可以以概率 $\frac{e^{\epsilon}+1}{e^{\epsilon}-1}$ 或 $-\frac{e^{\epsilon}+1}{e^{\epsilon}-1}$ 生成该用户的随机扰动值。

**编码**： 

$$
x=\operatorname{Encode}_{\mathrm{Duchi}}(v)=\frac{2 \cdot x}{b-a}+\frac{a+b}{a-b}
$$

**扰动**：

$$
\operatorname{Pr}\left[y=x' \mid x\right]=\left\{\begin{aligned} p=\frac{e^{\epsilon}-1}{2 e^{\epsilon}+2} \cdot x+\frac{1}{2}\quad & x'=\frac{e^{\epsilon}+1}{e^{\epsilon}-1} \\ q=\frac{1-e^{\epsilon}}{2 e^{\epsilon}+2} \cdot x+\frac{1}{2}\quad & x'=\frac{-e^{\epsilon}-1}{e^{\epsilon}-1} .\end{aligned}\right.
$$

为了获得 Duchi 机制的隐私保护程度，首先从输入集中随机选择一个数据，然后对该数据运行 $n$ 次，得到 $n$ 个输出。统计这 $n$ 个结果是否只有两个值，以及这两个值是否相反。如果是这样，则可以得到估计的 $\epsilon$，如果不是，则算法有错误。然后统计这两个值的出现概率是否符合隐私预算，如果不符合，则可以认为算法设计存在错误。为了确保计算的准确性，可以从输入集中再选择几个值，重复上述过程，并选择一个最大值作为结果。算法 4 提供了详细的伪代码。

```plaintext
算法4：Duchi 机制的测量函数
输入：$x'$，$\mathcal{Y}_c$
输出：隐私预算 $\hat{\epsilon}$
1. 函数 Measure\_Duchi($x'$，$\mathcal{Y}_c$)
2. $x:=|\mathcal{Y}_c[0]|$
3. $p:=0$
4. $q:=0$
5. $x':= \frac{e^{\epsilon}+1}{e^{\epsilon}-1}$
6. 对于 $i=1,2,...,n$
7. 如果 $\mathcal{Y}_c[i]=x$
8. $p:=p+1$
9. 否则，如果 $\mathcal{Y}_c[i]=-x$
10. $q:=q+1$
11. 否则，返回 $-1$
12. 结束循环
13. $\hat{\epsilon} = (\operatorname{In}(\frac{2x'}{x'-2p+1}-1)+\operatorname{In}(\frac{2}{|x'|-1}+1))/2$
14. 返回 $\hat{\epsilon}$
```

### 基于数据的隐私度量

 Differential Distinguishibility(DD) 为在 [1] 中提出的概念，用于度量一个隐私算法的保护能力。指的是对于一个隐私保护算法 $A: \mathcal{V} \rightarrow \mathcal{Y}$ ，如果满足 $\xi$-DD ，那么一定存在一个三元组 $\left(v, v^{\prime}, y\right)$ ，其中 $\left(v, v^{\prime}\right) \in \mathcal{V}$ 且 $ y \in \mathcal{Y}$ ，使得如下不等式成立：
$$
ξ \leq {\operatorname{In}{(\operatorname{Pr}\left[\mathrm{A}\left(v_{}\right)=y\right])}-\operatorname{In}({\operatorname{Pr}\left[\mathrm{A}\left(v^{\prime}\right)=y\right]})}
$$

本地差分隐私算法 $\mathrm{A}$ 在不同的输入下，隐私保护效果会有一定差异，尤其是在均值估计的环境下，这个差异尤为明显。如果一个本地差分隐私算法 $\mathrm{A}$ 的隐私预算为 $\epsilon$，表明即使在隐私泄露最高的情况下，最大隐私损失也不会大于 $\epsilon$ 。因此，如图 1 所示，如果 $\mathrm{A}$ 同时满足 $\xi$-DD 与 $\epsilon$-LDP，那么 $\xi $ 一定不大于 $ \epsilon$。可以将 Differential Distinguishibility 视为本地差分隐私的一个动态范围，$\xi$ 的最大值，即算法的最低隐私保护值。

若根据算法的输入输出度量隐私保护程度，需要计算出变量 $\xi$ 的最大取值。即找到能使得 $\xi$ 值达到最大的三元组 $\left(v, v^{\prime}, y\right)$ ，此时公式（2）可以取等号。

定义 2.  $L({v,v^{\prime},y})$ 为算法 $A$ 在输入为 $v$ ，输出为 $y$ 时的隐私泄漏程度，其计算方法为：
$$
L({v,v^{\prime},y}) := |{\operatorname{In}{(\operatorname{Pr}\left[\mathrm{A}\left(v_{}\right)=y\right])}-\operatorname{In}({\operatorname{Pr}\left[\mathrm{A}\left(v^{\prime}\right)=y\right]})}|
$$

定义 2 将算法的隐私泄漏程度，定义为了一个三元函数，函数的值域，便是隐私泄漏程度范围，而其最大值，则可视为算法的最大隐私泄漏值。通过输入与输出度量本地差分隐私算法的隐私保护程度，即找出合适的三元组 $\left(v, v^{\prime}, y\right)$ ，使得此时的 $L\left(v, v^{\prime}, y\right)$ 值达到最大，该值便是度量结果 $\hat{\epsilon}$ 。

#### Output value statistics

在从算法的输入域，选取输入值后，便需要统计这个值经过编码与扰动后的输出的概率分布。本地差分隐私算法的输出值可分为两类，同类值与组合值。

同类值：输出值为单个值或一组由同一类型值组成的向量值，该值被收集者接收后，将全部直接用于统计中。单一值如随机响应，duchi，分段机制等算法，这些算法的输出都为单个值，一般可以直接统计。向量值，如 sue，oue，he。这些算法的输出都为一个向量，虽然也可以直接视为单个值进行统计，但直接统计，会导致需要统计的值过多，造成较大的性能开销，需要进行更多处理。

组合值：输出并非单一值或者向量值，而是两个或多个不同功能值的组合。如： blh，olh。这些算法最终的扰动输出为哈希函数与单一离散值的组合，哈希函数不能直接进行统计，而是用于对离散值进行处理，处理后的值才能用于统计。这种类型的输出，需要提前知道哈希函数与输出值的关系，经过哈希值处理后，才能统计出算法输出的分布情况。

##### 同类值

同类值表示LDP算法的单次输出结果无论数量，都属于同一类型，可进行直接统计。总体又可分为：

* 输出为单个离散值算法，如：随机响应
* 输出为单个连续值的算法，如：duchi、分段机制
* 输出为多个离散值的算法： SUE、OUE 
* 输出为多个连续值的算法：HE

由于这些值都属于同一类型，因此可以直接通过数理统计，得出算法的输出值分布情况。

输出为同类值的算法 $\mathrm{A}$ ，要求得其在输入为 $v,v^{\prime}$ 时的隐私泄漏程度，即求出式（2）的最大值：
$$
L_{v,v^{\prime}}({y}) := |{\operatorname{In}{(\operatorname{Pr}\left[\mathrm{A}\left(v_{}\right)=y\right])}-\operatorname{In}({\operatorname{Pr}\left[\mathrm{A}\left(v^{\prime}\right)=y\right]})}|
$$
其中 $\operatorname{Pr}\left[\mathrm{A}\left(v_{}\right)=y\right]$ 为算法在 $\mathrm{A}$ 输入为 $v$ 时，输出为 $y$ 的概率。假设已经确定了相关输入值，则概率密度函数 $f_v(y)$ 表示算法 $\mathrm{A}$ 在输入为 $v$ 时输出的离散密度：
$$
f_{v}(y):=\operatorname{Pr}[\mathrm{A}(v)=y], \quad \forall y \in \mathcal{Y}
$$
此时，公式（2）可变形为公式（3）：
$$
L_{v,v^{\prime}}({y}) := |{\operatorname{In}{(f_{v}(y))}-\operatorname{In}({f_{v^{\prime}}(y)})}|
$$
$L_{v,v^{\prime}}$ 代表输入为 $v$，$v^{\prime}$ 时的隐私泄漏程度函数，$y$ 为自变量，定义域为算法的输出值范围 $\mathcal{Y}$，而其最终的隐私泄漏程度，则是隐私泄漏函数在定义域内的最大值 $max(L_{v,v^{\prime}}({y}) )$ 。

然而，除非算法的输出为单个离散值，在大多数情况下 $\operatorname{Pr}[A(v)=y]$ 的结果都难以估算。如果算法输出结果为向量值，随着输出结果的增加，输出结果的种类也会指数型增加。

> **例 1：**sue 算法，输出值为长度 100 的向量，每个向量位有 2 个不同的离散值。算法的输出为一个长度为 100 的向量，向量的每一位为 0 或 1。
>
> 那么，输出便有 $2^{100}$ 种不同的可能。
>
> 理论上，这 $2^{100}$ 种可能，其中，出现概率最高的值，出现的概率为：
> $$
> p = \frac{e^{\epsilon /2}}{\left(e^{\epsilon /2}+1\right)^{100}} \approx 8.19448 \times 10^{-43}
> $$
> 因此，要想估算结果以 95% 的置信率，误差在 $\pm 0.05\times10^{-43}$以内，理论上需要运行次数：
> $$
> n>\frac{p (1-p)}{\left(\frac{l}{2 z_{\frac{\alpha}{2}}}\right)^2} \approx 1.2592\times 10^{47}
> $$

由例 1 可知，算法在输入域为 100 时，要想统计出合理的输出值的分布情况，需要进行约 $1.2592\times 10^{47}$ 次运行，这会浪费极大的性能，甚至占用的内存会超过大部分计算机的最大内存。因此，不能直接将向量值无差别视为单个离散值，需要对向量值的每一位信息进行保留，对向量的每一位进行统计，间接计算出 $\operatorname{Pr}\left[\mathrm{A}\left(v_{}\right)=y\right]$ 的值，即计算出算法输出向量每一位的输出分布，得出每一位的输出分布情况。

向量值输出概率的计算：

在输出为离散向量的情况下，算法的输入为 $v$ 时，算法的输出记为 $y$，假定 $y$ 有 $k$ 位，则 $y={y_1 \times y_2 \times \cdots \times y_k}$ ，其中 “$\times$” 代表笛卡尔积，令 $t\isin \mathcal{Y_1}\cup\mathcal{Y_2}\cup\cdots\cup\mathcal{Y_k} $，$\mathcal{Y_i}$ 为输出向量第 $i$ 位的值的集合，在向量的每一位不会互相影响时，向量第 $i$ 位的输出分布为：
$$
f_{v}^i(t): = { \operatorname{Pr}(A_i(v)=t)}
$$
向量中的 $k$ 位相乘，即可得到总体 $y$ 的分布：
$$
f_{v}(y): = \prod \limits_{i = 1}^{k} { \operatorname{Pr}(A_i(v)=t)}  \quad\forall t\isin \mathcal{Y}_1\cup\mathcal{Y}_2\cup\cdots\cup\mathcal{Y}_k
$$

根据公式（2）可得推论（3）：
$$
\begin{align*}
L_{v,v^{\prime}}({y})

&= |{\operatorname{In}{(f_{v}(y))}-\operatorname{In}({f_{v^{\prime}}(y)})}| \\

&= |{\operatorname{In}{(\prod \limits_{i = 1}^{k} f^i_{v}(t))}-\operatorname{In}({\prod \limits_{i = 1}^{k}f^i_{v^{\prime}}(t)})}| \\

&= |{\sum_{i=1}^k\operatorname{In}{(f^i_{v}(t))}-\sum_{i=1}^k\operatorname{In}({f^i_{v^{\prime}}(t)})}| \\

&= {\sum_{i=1}^k | \operatorname{In}{\left(f^i_{v}\left(t\right)\right)}-\operatorname{In}\left({f^i_{v^{\prime}}\left(t\right)}\right)} |


\end{align*}
$$
如果算法的输出为连续值，那么可直接通过数理统计的方式进行计算。如果算法的输出结果为连续值，或算法的输出为多个连续值组成的向量，则算法的输出结果无法直接通过简单的数理统计得出分布情况。因此连续算法和离散算法同样要分情况考虑，在统计前需要对算法的输出进行判断。这特别有助于我们处理连续算法的问题。详细来说，连续算法需要考虑定义域上所有值，因此要考虑的输出值是无限大的。在实际情况中，可以考虑将输出空间离散化，如，可以假设输出区间为 $n$ 个等距离的离散点。就精度而言，分成的点越多，计算出的值就会越精确。

然而，随着分割的细化，每个区间的值的数量将会不断减少，在区间足够小时，每个区间有可能仅落入几个点或没有点，此时会给隐私泄漏值的计算带来很大的误差。

为了解决这个问题，本文将使用核密度估计方法（kernel density estimation）：核密度估计提供了更渐进的信息，即算法输出接近于真实分布的概率，这在连续情况下使用该方法更为准确。尽管直接采样很难得到精确的概率密度分布，甚至从理论上讲是不可能的，但只要采样数据足够多，能得到接近真实的值。即使在概率很小的区间，核密度估计也能得到比较平滑的值。最后，文中提到更多理论知识可以参考文章的第二部分。

连续值将使用核密度估计法进行分布估计，其余内容与离散情况并无差别。

##### 组合值

并非所有算法都可以直接将算法的输出纳入统计，比如，BLH 与 OLH 算法，这些算法在编码扰动后的输出值为哈希函数与扰动结果的组合，只有扰动结果才能进行度量，哈希函数只能用于辅助度量，不能直接参与。

要想通过此类输出，度量隐私保护程度，则需要提前知道相关哈希函数与扰动值的关系，否则无法进行直接度量。

#### Statistical threshold

由公式 L（3） 可知，算法的隐私泄漏值为输出向量每一位的隐私泄漏值的累加和（单个值可视为长度为 $1$ 的向量）。
$$
L_{v,v^{\prime}}({t}) = {\sum_{i=1}^k L^i_{v,v^{\prime}}({t}) }
$$
然而，每一次计算隐私泄漏值 $L^i$，都会存在一定的误差，多次计算会造成误差的累加，从而对结果产生影响。

假定，输入值为 $v,v^{\prime}$ 时，输出值在第 $i$ 位上有着相同的分布，对算法进行 $n$ 次运行后，$\hat{f_i}$ 的 95% 置信区间为 $[f_i-l,f_i+l]$ ，
$$
\begin{align*}

L^i_{v,v^{\prime}}({t}) &=|\operatorname{In}{\left(\hat{f^i_{v}}\left(t\right)\right)}-\operatorname{In}\left({\hat{f^i_{v^{\prime}}}\left(t\right)}\right)|
\\
&=|\operatorname{In}\frac{f^i_{v}(t)}{f^i_{{v}^{\prime}}(t)}|

\end{align*}
$$
由于对数函数的性质，在 ${f_i}$ 的值很小时，即便估计出的 $\hat{f_i}$ 值有着极小的误差，也会因对数函数，将其放大到很大值。

<img src="/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20231212162301134.png" alt="image-20231212162301134" style="zoom:33%;" />

如图：展示了函数 $\operatorname{In}(\frac{x-0.05}{x+0.05})$ 的分布情况，即两个相同分布的变量，在估算误差为 $\pm 0.05$ 时的结果误差。由图可以看出，在 $x<0.2$ 时，最终误差开始快速升高。

> **例 2：** sue 算法 $A$，输入域为 $D=\{1,2,\cdots,100\}$ ，隐私预算 $\epsilon=0.5$ 。输出值为长度 100 的向量，每个向量位有 2 个不同的离散值 0 或 1。
>
> 根据 sue 的性质，算法的输入将会被编码为长度为 100 的向量，其中 1 位为 1，其余位为 0，然后再进行扰动，每一位以 $\frac{1}{1+e^{\epsilon/2}}$ 的概率发生变化。因此在扰动后，两个不同的输入它们的输出仅有 2 位会存在分布差异。其余位虽然分布理论上没有差异，但是，由于统计的误差，仍能计算出较小的隐私泄漏值。
>
> 在本例中，如果将该算法运行 10000 次，那么最终实验结果中，计算其中 98 位理论上为 0 的隐私泄漏值。实际值大多在 0.001-0.02之间，累加后的值大于 1。^[1]^ 
>
> 而其中 2 个不同位的值，最终的隐私泄漏和理论上为 0.5 ，实际值约为 0.51，误差较小。

由以上案例可知，在计算前，排除掉分布相同的位可以有效减小误差。

**判断离散变量是否满足同一分布**，主要采用了信息论中的 $\operatorname{JS}$ 散度进行计算。当变量满足一定的阈值时，便认定该变量有着相同分布，此时的隐私泄漏程度为直接记为 0。根据 $\operatorname{JS}$ 散度性质，两组变量越是接近于同一分布，则 $\operatorname{JS}$ 散度值越接近于0，差距越大则更接近于1。

不过即使理论上算法的输出在该位上满足同一分布，在输出时由于随机性，很难保证两轮输出的值分布完全相同，其 $\operatorname{JS}$ 散度接近于0而不等于0，输出值的种类越多，值会越大。同样，两组不同分布的变量，变量值的类型越少，相对的 $\operatorname{JS}$ 散度值也会减小。

因此，需要确定一个 $\operatorname{JS}$ 散度阈值 ，保证在值分布相同时，小于该值的可被判定为相同，大于该值的可被判定为不同，该阈值需根据算法输出向量中的变量数量而定，大多数算法的值种类仅为 2，也就是值为 0 或 1 ，为保证通用性，在测试相同阈值时，假定输出的值中，有 10 个不同的变量，在测试不同阈值时，假定输出的值中，仅有 2 个不同的变量。

为确定 JS 散度的合适值，需要考虑各种极端情况。在 $n=40000$ 时（n 的取值方法在第 5 章有详细说明），如果变量集有 10 个不同的值，且每个值的出现频率都为 $\frac{1} {10}$ ，则此时计算 JS 散度，95%的情况下值小于0.0001。

<img src="/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20230615213504212.png" alt="image-20230615213504212" style="zoom:67%;" />

在 $n=40000$ 时，如果变量集有2个不同的值，且每个值的出现频率为 $\{0.49,0.51\}$，则此时95%的值大于0.0001。

<img src="/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20230616101427788.png" alt="image-20230616101427788" style="zoom:67%;" />

因此选择阈值0.0001，可满足大多数需求，且最大程度上减小误差。

因此，输出向量每一位的误差可描述为：
$$
\begin{equation}

L^i_{v,v^{\prime}}({t})=

\left\{\begin{array}{ll}

|\operatorname{In}\frac{f^i_{v}(t)}{f^i_{{v}^{\prime}}(t)}| 

&  \operatorname{JS}(f^i_{v},f^i_{{v}^{\prime}})>0.1 \\ 

0

& \operatorname{JS}(f^i_{v},f^i_{{v}^{\prime}})\leq 0.1 

\end{array}\right.
\end{equation}
$$
**判断连续变量是否满足同一分布（+图）** 。

同样，在处理连续数据时，如果两个连续值满足同一分布，那么他们，不过与离散值不同，无法直接使用 JS 散度的大小进行判断。

由于连续数据的统计需要使用核密度估计法。在核密度估计后，如果两个变量有着相同的分布，那么其核密度估计的结果理论上也应该相同。不过由于误差，即使有着相同的分布，两个分布做差后，结果大致在（0.01-0.05）之间。

本实验中，使用 0.05 作为阈值，用于衡量两组变量是否相同，如果两组变量的差异小于相应阈值，则认为两组变量有着相同的分布。

#### Privacy measurement code

输入：要度量的LDP算法 $A$，该算法的输出为长度为 $d$ 的向量值，算法输入的值集合：  $V=\{v_1,v_2,...v_m\}$ 

输出：算法的隐私泄露值 ${\epsilon}_{avg}$ 

**function** OB_Measure($A$ , $V$ ,countinue) ：

​	$t=max( \lceil In(d)\rceil,2)$ 

​	// 随机选择 $t$ 个输入值

​	$V^{\prime}$ = RandomSelection($Data$ , $t$ ) 

​	$V^{\prime} = [v_1^{\prime},v_2^{\prime},...,v_t^{\prime}]$ 

​	// 将这 $t$ 个输入值，输入算法 $A$ 中，运行 n 次：

​	$X_{ij}=A(v_i^{\prime})\space\space\space\space\space\space i\isin\{ 1,2,...,t \}\space\space\space\space\space\space j \isin\{ 1,2,...,n\}$ 

​	// 核密度估计法，构造函数 f(x)

​	$	f_{i}^{k}(x)$ = KernelDensityEstimation($X_{i1}^k,X_{i2}^k,...,X_{in}^k$)             $i\isin\{ 1,2,...,t \}\space\space\space\space\space\space k \isin\{ 1,2,...,d\}$ 

​	**for**	$(i,i^{\prime})$  **in**  $((1,2),(1,3),...,(1,t),(2,3),(2,4),...,(t-1,t))$ :

​			$\hat{\epsilon}_a  = \sum^{d}_{k=1} max(|In(f_{i}^{k}(x))-In(f_{i^{\prime}}^{k}(x))|)$ 

​	**end for** 

**return**  $max(\hat{\epsilon})$ 



$t=\lceil {log_2e^\epsilon+1} \rceil$

输入：

1. 要度量的LDP算法 $A$ 
2. 算法输入值集合：  $V=\{v_1,v_2,...v_d\}$ 
3. 算法 $A$ 扰动值的 comb 函数，用于将输出转换为可统计的同类值，如果算法 A 的输出本身为同类值，则函数内不进行任何操作。

输出：算法的平均隐私泄露值 ${\epsilon}_{avg}$ ，最大隐私泄露值 ${\epsilon}_{max}$ 。

执行步骤：

**运行算法：**

遍历集合 $V$ ，将集合中的每个元素输入算法 $A$ 中 $n$ 次，记录每一次运行的结果，算法输出集合记为：

$Y_{ij}=comb(A(v_i))\space\space\space\space\space\space i\isin\{ 1,2,...,d \}\space\space\space\space\space\space j \isin\{ 1,2,...,n\}$ ，$Y_{ij}$ 表示算法在输入为 $v_i$ 时，第 $j$ 次运行的输出。

如果被测试算法为同类值，则 $comb$ 函数直接返回算法 $A$ 的输出值；如果算法为组合值，则 $comb$ 函数将组合值转换为可一起统计的同类值，再进行计算，函数的具体内容需要根据算法进行设定。

**统计结果：** 

将输出值 $Y_{ij}$ 视为长度为 $k$ 的向量，统计向量每一位的输出值的概率，构造密度函数 $f_{v_i}^{k}(t)$ 。

​	$f_{v_i}^{k}(t)$ = DensityEstimation($Y_{i1}^k,Y_{i2}^k,...,Y_{in}^k$) 

​	$f_{v_i}^{k}(t)$ 表示，输入为 $v_i$ 时，输出变量中第 $k$ 位的分布函数。

**隐私泄漏值计算：** 

从所有密度函数中，选取两个不同输入值 $v_i$ 与 $v_j$ 的输出分布函数：

$[f_{v_i}^{1}(x),f_{v_i}^{2}(x),\cdots,f_{v_i}^{k}(x)]$ 与 $[f_{v_j}^{1}(x),f_{v_j}^{2}(x),\cdots,f_{v_j}^{k}(x)]$ 

将这 $k$ 对分布结果两两比较，比较对应位是否分布相同，离散变量计算 JS 散度是否小于设定阈值 $\tau_d$，连续变量则两函数相减后的新函数最大值是否小于设定阈值 $\tau_c$ 。如果小于设定阈值，则将这对函数替换为值 1。

隐私泄露值 ${\epsilon}_{v,v^{\prime}}$ 计算：
$$
\hat{\epsilon}_{v,v^{\prime}}  = \sum^{d}_{k=1} max(|\operatorname{In}(f_{i}^{k}(x))-\operatorname{In}(f_{i^{\prime}}^{k}(x))|)
$$

最大隐私泄露值 $\hat{\epsilon}_{max}$ 与平均隐私泄漏值 $\hat{\epsilon}_{avg}$ 计算：
$$
\begin{equation}
\left\{\begin{array}{ll}

\hat{\epsilon}_{max} = max(\hat{\epsilon}_{v_i,v_j}) , 

&  \\ 

\hat{\epsilon}_{avg} = mean(\hat{\epsilon}_{v_i,v_j}) , 

& 

\end{array}\right.
\end{equation}



\\ \quad i≠j \quad i,j\isin{1,2,\cdots,d}
$$



### 实验分析



### 本章小结





## 匿名数据的度量（20）

当前，数据拥有者通常需要将自己收集到的数据交予其他机构进行数据分析或向公众发布。为了防止用户隐私信息的泄露，在发布或共享数据前，往往需要对数据进行匿名处理，达到一定隐私保护程度后才可安全发布。因此衡量发布数据的隐私保护水平是一项重要的研究内容。由于在以往的研究中，缺少足够通用的方案，不能对发布数据的隐私保护水平进行精确度量。本章节因此提出了一种度量发布数据隐私保护程度方法，该方法主要通过条件熵与互信息，度量出数据处理前后的差异值，在此基础上基于互信息和联合熵融合得到具体的隐私保护效果，最终输出一个0~1范围的数值精确表示发布数据的隐私保护水平。将该方法应用到真实的数据集中，在匿名处理数据集使其满足常用的隐私模型后，分别度量不同隐私模型下数据各个属性的隐私保护水平，证明了所提方法的有效性。

### 引言

当前， 政府和企业需要统计分析大量的个人数 据以便更加准确地决策。 而这些数据在收集整理后， 不仅有可能会在各组织之间传播， 还有可能直接在 公共领域发布。 数据收集和发布的过程很容易泄露用户的隐私[1] 。 因此， 在发布数据前， 需要为这些数 据提供足够的隐私保证。 如发布人口普查数据、医 院的患者治疗数据时[2] ， 对这些数据进行有效的分析 可以帮助政府进行政策的制定， 还可以帮助医疗科 研人员找到更好的疾病治疗方法。 但是， 这些数据 往往含有大量的个人隐私信息， 如家庭住址、疾病信息等。 直接将数据给予研究组织会侵犯个人隐私。 尽管直接能明确识别用户的属性往往会在发布前被 删除， 但在实际应用中， 通过剩余的信息仍然有可 能对应到个人数据[3] 。 为了避免上述问题的发生， 隐私保护的数据统计分析（Privacy-Preserving Statistical Analysis, PPSA）研究应运而生。

在PPSA研究中，主要包含5种实体：数据提供方、数据管理方、数据使用方、隐私敌手、数据。数据提供方为数据的来源，通常为个人用户。数据管理方负责从数据提供方收集数据，并将数据进行脱敏处理后交给数据使用方。数据使用方通常为科研工作者。隐私敌手通常代表试图从数据中获取个人隐私数据的数据使用方，数据管理方也有可能是隐私敌手。

对数据的处理是整个隐私保护过程的关键，针对不同类型的数据，需要有不同的处理方式。一般需要公布的数据集属性可分为4类：识别符（Identifiers）、准识别符（Quasi-identifiers）、敏感属性（InsensitiveAttributes）、不敏感属性（SensitiveAttributes）。识别符表示能明确识别受访者的属性（如身份证号），在数据发布前需要删除或部分删除该信息。准识别符表示可与外部来源或数据库相连接或结合，以重新识别用户的属性（如姓名、年龄、邮政编码）。这些属性无法单独直接找到用户，但是这些属性结合起来，可降低找到用户的难度。不敏感属性表示不包含任何用户隐私信息的属性。敏感属性表示包含用户隐私信息的属性，其公开会导致直接侵犯用户隐私（如薪资、家庭住址）。

按照隐私攻击的目标，隐私敌手的攻击主要可以分为身份攻击、属性攻击、存在性攻击和概率知识攻击4种。其中，身份攻击假定隐私敌手已有关于攻击目标的准识别符信息作为背景知识，且确定该攻击目标存在于数据管理方的数据集中。身份攻击期望从发布的数据集中得知攻击目标所对应的数据条目。属性攻击假定隐私敌手已知该攻击目标存在于数据管理方的数据集中，期望从发布的数据集或者查询结果中得知（或概率性地得知）攻击目标在数据集的属性值。相比于身份攻击，属性攻击不一定需要获取攻击目标对应的数据条目。存在性攻击期望从数据管理方发布的数据集或者查询结果中得知攻击目标是否存在于数据管理方的数据集中。概率知识攻击是在隐私敌手具有某些部分包含不确定性（概率性）的先验背景知识的情况下，期望通过分析数据管理方发布的数据集或者查询结果，降低背景知识的不确定性。

从以上4种攻击方式来看，隐私保护的核心目标，是改变原始数据，从而增加隐私敌手从发布的数据中找到目标信息的难度[4]。而对原始数据进行处理，首先要删除识别符，或者将识别符部分隐藏（如只显示部分身份证号或手机号），防止目标信息被直接定位。其次，降低准识别符的信息量，使得一条准识别符能对应出多个条目。同样也要降低隐私信息与准识别符的关联程度，使得准识别符对应的多个条目中，包含不同种类的隐私信息。对这些数据进行修改的过程，被统称为“消毒”（Sanitization）。

具体而言，本文通过条件熵与信息熵，计算出数据处理前后具体的差异值与准识别符和隐私属性的联系程度，进而得到本文求得的数据隐私保护程度值PL（PrivacyLevel）。我们首先对匿名处理前后的数据集的各种属性按照类别进行划分，并分别做好标记。随后，我们定义了计算PL值的公式，该公式的核心目标是计算出通过准识别符信息得到隐私数据的难度和通过匿名后的隐私数据推理出原始的隐私信息的难度，二者的结合便是隐私保护水平，难度越高则表示隐私保护程度越高。将同一数据集的不同属性代入公式可得到不同的数值，进而得出不同属性的隐私保护水平，也就是局部隐私保护水平。将同类属性进行合并，并代入公式便得到数据集整体的隐私保护水平。

本文的主要章节内容介绍：第2节介绍了要想度量发布的数据，使用的“消毒”机制需要满足哪些特征；第3节介绍了度量前需要构建的理论模型；第4节介绍了本文提出的隐私保护水平的重要指标 PL的定义第5节将匿名化后的微型数据库代入 PL 计算的公式中，以此来说明 PL 的实用性；第6节介绍了在真实的数据集上的 PL 值的计算；第7节是我们的结论与未来的研究方向。

### 系统模型与信息论基础

#### 隐私保护的数据统计分析（PPSA）



#### 系统模型

本文使用 $D$ 表示原始数据集。该数据集为一张表，表中有 $K$ 列数据，每一列数据代表一种属性。 $\mathcal { K }$ 表 示所有属性的集合，表中共有 $n$ 行数据。 $X ^ { k }$ 表 示属性 $k$ 的所有数据， $k \in \mathcal { K } 。 X _ { i }$ 表示第 $i$ 行数据， $i \in$ $\{ 1 , 2 , \ldots , n \} $。 因此 $X_{i} = \left(X_{i}^{1},X_{i}^{2},⋯,X_{i}^{k}\right),\:X^{k} = \left(X_{1}^{k},X_{2}^{k},⋯,\right.$ \[\left. X _ { n } ^ { k } \right) 。\] 

属性集 $\mathcal { K }$ 中的属性可划分为4类：识别符 $\mathcal { K } _ { \mathrm { i d } } 、$ 准识别符 $\mathcal { K } _ { \mathrm { q d } } 、$ 不敏感属性 $\mathcal { K } _ { \mathrm { p u b } } 、$ 敏感属性 $\mathcal { K } _ { \text{prv} } 。 $ 在匿名模型中，这4类属性是互斥的，满足 $\mathcal { K } = \mathcal { K } _ { \mathrm { i d } } \cup \mathcal { K } _ { \mathrm { q d } } \cup \mathcal { K } _ { \mathrm { p u b } } \cup \mathcal { K } _ { \mathrm { p r v } } 。$

然而在实际应用中，许多属性难以界定，如公开一个医院的疾病诊断数据，病人的年龄理论上不属于隐私属性，而是准识别符。但是有许多病人也不愿意透露自己的真实年龄。这就导致了这个属性既有可能是准识别符，也有可能是隐私属性。本文提到的度量模型也能够度量这种情况下准识别符的隐私泄露程度。 

与原始数据集的表示略有不同，在本文中经过匿名后的数据集表示为 $\bar { D } $。 匿名后的数据表的4种不同的属性分别为：识别符 $\overline { \mathcal { K } } _ { \mathrm { i d } } 、$ 准识别符 $\overline { \mathcal { K } } _ { \mathrm { q d } } 、$ 不敏感属性 $\overline { \mathcal { K } } _ { \mathrm { p u b } } 、$ 敏感属性 $\overline { \mathcal { K } } _ { \mathrm { p r v } } $。 同样，匿名后的数据表示为 $\bar { X } $。 

Snakar等24]使用条件熵的方式定义了隐私 $( \mathcal { P } )$ 的具体概念： 
$$
\mathcal { P } = H \left( X _ { \mathrm { p r v } } \mid X _ { \mathrm { P U B } } \right)
$$
式中 $X _ { p r v }$ 表示隐私数据， $X _ { P U B }$ 表示数据集中除了隐私数据外的其他所有信息，包括识别符、准识别符、不敏感信息，这些信息都会减少隐私敌手获取隐私信息的难度； $H \left( X _ { \mathrm { p r v } } \mid X _ { \mathrm { P U B } } \right)$ 表示给定一些相关公共数据 $X _ {  { P U B } }$ 后，隐私数据 $X _ { \mathrm { p r v } }$ 剩余的信息量。 

#### 信息论基础

在我们的工作中同样使用了信息论的相关概念进行隐私度量，因此该隐私模型最适合本研究使用。 此模型在度量隐私时，无需考虑数据处理过程，因此无论使用泛化还是微聚集的方式，都不会造成差异。处理后数据的不同分布与关联才会影响到度量结果。 

信息熵、条件熵、互信息和联合熵是信息论中的基本概念，用于衡量信息、不确定性和信息之间的关系。在隐私度量中，主要使用这几个基本概念，度量数据集中的隐私保护程度。

**信息熵**

数据 $X$ 的信息熵通常表示为： $H(X)$。是衡量一个随机变量不确定性的量，它表示了数据集 $X$ 中包含的信息量。较高的熵意味着变量的不确定性较大，因此信息量也更大。在计算机中，可理解为表示事件 $X$ 需要多少二进制位。信息熵的公式（香农公式）为：

$$
H(X)=-\sum_{x\in X } p\left(x\right) \log_2{p\left(x\right)}
$$
信息熵越大，表明要想了解这个信息，需要更多的数据，信息熵越小，则所需数据越少。

**条件熵**

数据 $X$ 与 $Y$ 的条件熵可表示为： $H(Y|X)$。衡量在已知随机变量 $X$ 的条件下，随机变量 $Y$ 的不确定性。它反映了当我们知道变量 $X$ 的值时，变量 $X$ 的剩余信息量。同样可理解为在已知事件 $X$ 后，表示事件 $Y$ 需要多少二进制位。联合熵的公式为：

$$
\begin{aligned} H(Y \mid X) &=\sum_{x \in X} p(x) H(Y \mid X=x) \\ &=-\sum_{x \in X} p(x) \sum_{y \in Y} p(y \mid x) \log_2 p(y \mid x) \\ &=-\sum_{x \in X} \sum_{y \in Y} p(x, y) \log_2 p(y \mid x) \end{aligned}
$$

**互信息**

数据 $X$ 与 $Y$ 的互信息可表示为：$I(X;Y)$ 。用于衡量两个随机变量之间共享的信息量，即知道变量 $Y$ 的值减少了对变量 $X$ 不确定性的多少，反之亦然。互信息的公式为：

$$
\begin{aligned} I(X, Y)
&=\sum_{x,y}p(x,y)\log_2\frac{p(x,y)}{p(x)p(y)}\\
&=H(Y)-H(Y \mid X) \\ 
&=H(X)-H(X\mid Y)
\end{aligned}
$$
**联合熵**

数据 $X$ 与 $Y$ 的联合熵可表示为：$H(X,Y)$ 。用于衡量两个随机变量 $X$ 和 $Y$ 作为一个整体的不确定性。它表示同时表示 $X$ 和 $Y$ 时，所需要的信息量。联合熵的公式为：
$$
H(X,Y) = -\sum_{x,y}p(x,y)\log_2 p(x,y)
$$
其中，$p(x,y)$ 是 $X$ 和 $Y$ 的联合概率分布。

总结：

![image-20220714201635042](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20220714201635042.png)

### 隐私度量

#### 整体隐私保护程度的度量

为了便于计算，我们将属性值视为离散随机变量集合，而匿名后的数据集，可被视为另一个数据类型相对更少的离散随机变量集。首先，我们需要度量出隐私属性 $X_{prv}$ 与准识别符 $X_{pd}$ 的识别率（Discrimination Rate） [1]，识别率是在 [1] 中提出的相关概念。识别率度量隐私泄漏程度的核心在于，在获得了准标识符的情况下，能获得多少对隐私信息的认识，使得隐私信息的信息熵减少了多少。减少得越多，说明准标识符提供的信息越多，隐私泄漏能力越强。

不过，单纯度量出识别率无法真正确定隐私泄漏程度，因为在真实的数据消毒过程中，被消毒的，往往不止准标识符信息，隐私信息同样可以被处理，处理后的隐私信息即使被泄漏，也不能就此认定用户的真正隐私信息被泄露。因此在度量隐私泄漏程度时。首先要基于发布的数据，度量发布信息的泄露程度，再结合度量原始隐私信息与消毒后隐私信息的差异。从而得出最终的隐私泄漏结果。
$$
PL(\overline{X}_{prv})=\underbrace{\left(1-\frac{H(\overline{X}_{prv}|\overline{X}_{pd})}{H(\overline{X}_{prv})}\right)}_{DR({\overline{X}_{pd}},\overline{X}_{prv})}\times\frac{I({X}_{prv},\overline{X}_{prv})}{H({X}_{prv})}
$$

上式中， ${H(\overline{X}_{prv}|\overline{X}_{pd})}$ 表示隐私列与准标识符列的条件熵，可以用来表示，在数据经过消毒并发布后，隐私敌手可通过准标识符信息，让隐私信息的信息熵减少量是多少。其与消毒后隐私信息的信息熵 $H(\overline{X}_{prv})$ 的比值，便是隐私信息剩余的比例，其值越大，表明准标识符对定位隐私信息提供了较小的帮助，最大值为 1；同样，其值较小时，表明即使在消毒处理后，准标识符还是能大量降低隐私信息的信息熵，隐私敌手仍然很容易获取到隐私信息。由于二者的比值在 0 到 1 之间，因此在 1 减去二者的比值便是识别率。识别率越高，隐私保护程度越高，在 DR=1时，每个准标识符都能直接定位到一个信息，则可将该准标识符视为标识符；在 DR=0时，被称为零标识符，此时该数据无法提供任何信息，大多数情况下，此时所有准标识符信息完全相同，数据已经丧失效用。

式 ${I({X}_{prv},\overline{X}_{prv})}$ 度量的是原始隐私数据与消毒后隐私数据的互信息，可认为是在经过消毒处理后，原始信息中被保留住的信息量，该值会随着消毒程度的增加而减小。若该数据未经处理，那么二者的互信息与原始数据的信息熵应当相同，即 ${I({X}_{prv},\overline{X}_{prv})}$ 与 ${H({X}_{prv})}$ 的比值为 1。此时若消毒后的隐私被泄露，那么同样可被认为原始的隐私信息被泄露。

由上述描述可知，乘法左右的数据都是在接近于 1 的时候隐私泄漏程度最高，同时在接近于 0 的时候隐私泄露程度最小。因此最终得出的隐私保护水平 PL 值也在 0 到 1 之间。越接近于 0，表明隐私保护水平较高，越接近于 1，表明隐私保护水平较低。

#### 局部隐私保护程度的度量

上述的隐私属性与准标识符属性只适用于大多数情况。不过，如 3.1 节所述，数据的隐私属性与准标识符属性并非互斥的，一个数据在某些情况下可同时被视为隐私属性与准标识符属性，因此在对数据类型进行划分时，也要考虑到一些特殊情况。

假定 X 为隐私数据，Y 为隐私敌手已经知道的隐私数据。那么隐私保护水平的计算公式可由上述公式变形而来：
$$
PL_{Y}(\overline{X})={\left(1-\frac{H(\overline{X}|\overline{Y})}{H(\overline{X})}\right)}\times\frac{I({X},\overline{X})}{H({X})}
$$

其度量方式与整体隐私保护程度度量的公式几乎相同，只是将隐私属性替换为了任意属性 $X$ ，即使对于大多数人都默认的非隐私属性，如出生年月，生活城市等也可代入，对于一些特殊人群的隐私也需要进行度量。准标识符属性替换为了除隐私属性外的其他任意属性，该属性是在大多数情况下每个人都能合法获取到的属性，如手机号、邮箱等。

### 隐私保护度量实例分析

#### 数据匿名样例

本节将使用一个简单的样例来说明我们的度量方法在不同的隐私模型中的度量结果。 我们在 3 个 常用的匿名模型上进行实验， 即 k-匿名、l-多样性 和 t-closeness。

原始数据

|      | ZIP Code | Age  | Salary | Disease        |
| ---- | -------- | ---- | ------ | -------------- |
| 1    | 47677    | 29   | 3K     | gastric ulcer  |
| 2    | 47602    | 22   | 4K     | gastritis      |
| 3    | 47678    | 27   | 5K     | stomach cancer |
| 4    | 47905    | 43   | 6K     | gastritis      |
| 5    | 47909    | 52   | 11K    | flu            |
| 6    | 47906    | 47   | 8K     | bronchitis     |
| 7    | 47605    | 30   | 7K     | bronchitis     |
| 8    | 47673    | 36   | 9K     | pneumonia      |
| 9    | 47607    | 32   | 10K    | stomach cancer |

消毒后的数据

|      | ZIP Code | Age  | Salary | Disease        |
| ---- | -------- | ---- | ------ | -------------- |
| 1    | 4767*    | ≤40  | 3K     | gastric ulcer  |
| 2    | 4767*    | ≤40  | 4K     | gastritis      |
| 3    | 4767*    | ≤40  | 5K     | stomach cancer |
| 4    | 4790*    | ≥40  | 6K     | gastritis      |
| 5    | 4790*    | ≥40  | 11K    | flu            |
| 6    | 4790*    | ≥40  | 8K     | bronchitis     |
| 7    | 4760*    | ≤40  | 7K     | bronchitis     |
| 8    | 4760*    | ≤40  | 9K     | pneumonia      |
| 9    | 4760*    | ≤40  | 10K    | stomach cancer |

上表（1）为原始数据表，表（2）为匿名处理后可用于发布的新表。

上述数据选自于[1], 原始数据表（1）共有 4 列，ZIP Code（邮政编码）、Age（年龄）、Salary（薪资）、Disease（疾病）。ZIP Code 列与 Age 列均没有重复值，也就是说这两列数据均可视为标识符使用。Salary（薪资）与 Disease（疾病）为隐私数据列，隐私保护的核心目标，便是防止隐私敌手通过已知的相关信息将某一行的隐私数据与某个用户对应上。

表（2）为修改后的数据，ZIP Code列的数据均只精确到倒数第二位，最后一位置为："*"。Age列不再提供精确的年龄，而是以 40 为界，提供年龄的范围。这样修改后，准标识符列虽然有 9 组数据，却只存在 3 个不同的元组：{(4767\*, ≤40),(4790\*, ≥40),(4760\*, ≤40)} 。每个元组有 3 行数据。该数据满足 3-anonymity ，此时隐私敌手无法确认自己手中的数据精确属于哪一个用户，每次只能锁定 3 行。如隐私敌手知道被攻击用户的邮政编码与年龄为(4767\*, ≤40)，然而从公开的数据来看，1-3 行均满足要求，无法确定用户的薪资与疾病。同时，处理后的数据满足 3-diversity ，因为每条修改后的准标识符，都能找到 3 组不同的隐私数据。如(4767\*, ≤40)对应于 3 组不同的数据：{(3K, gastric ulcer),(4K, gastritis),(5K, stomach cancer)}，其他几个准标识符元组同理。同时，表中的薪资列满足 0.167-closeness，疾病列满足 0.278-closeness。疾病列内有更多的重复数据，因此 t 值相对较高。

#### 隐私保护水平度量

由于所使用的数据集较小，可较为直观地观察到原始数据集与处理后数据集的差异。而隐私保护水平可直接进行计算。基于上述方法与数据，对一些关键的隐私保护水平进行度量。

1、整体隐私保护程度的度量

隐私列（Salary，Disease） 与准标识符列（ZIP Code， Age），将两列数据合成为 1 列数据，同一行的数据合成为 1 个元组。

$PL(D) \approx (1-1.58/3.17)\times3.17/3.17 = 0.5$ 

由于两列的隐私数据在消毒前后并没有变化，因此，消毒前后隐私信息的互信息与原始隐私信息的信息熵相等。即消毒后的隐私信息与原始信息呈一一对应的关系。$\frac{H(\overline{X}_{prv}|\overline{X}_{pd})}{H(\overline{X}_{prv})}\approx0.5$ 表明隐私敌手可以通过消毒后的准标识符缩小隐私信息的范围，但是无法直接确定一个准标识符。各个计算值都符合实际情况。

2、Salary 列与准标识符列隐私水平

$PL_{K_{pd}}(K_{S}) \approx (1-1.58/3.17)\times3.17/3.17 = 0.5$ 

可以观察到，$PL_{K_{pd}}(K_{S})=PL(D)$ 而且不仅仅结果相同，里面的计算单元也完全相同。这是由于两组计算的准标识符列完全相同，而整个数据的隐私列构成的元组列表（Salary，Disease）有 9 个不同的值，单个Salary同样也有 9 个不同的值，这就导致了量列的信息熵与条件熵相同。

3、Disease 列与准标识符列隐私水平

$PL_{K_{pd}}(K_{D}) \approx (1-1.58/2.50)\times2.50/2.50 = 0.37$ 

对 Disease 列的隐私保护水平的计算明显与Salary不同，Disease 列仅仅有 6 个不同的数据，也就导致了该列的信息熵要低于 Salary 列，理论上更容易发生隐私泄漏。然而该列与准标识符的条件熵却与 Salary 列与准标识符的条件熵相等。这说明了通过准标识符，对 Salary 列的了解程度会有所增加，但是信息量更少的 Disease 列也会增加到同样的水平，说明了该列的隐私保护水平要高于 Salary。这符合实际情况，由于消毒后的数据满足 3-diversity，隐私敌手通过准表示符，与 Salary 列相同也只能锁定 3 个不同的 Disease 信息。

4、Age 与 ZIP Code 列隐私水平

$PL_{K_{Z}}(K_{A}) \approx (1-0/0.92)\times0.92/3.16 = 0.29$ 

与上述 3 个度量不同，Age列并非隐私属性，在进行数据消毒时，虽然对该列进行了修改，但修改的目的是为了保证隐私列的数据达到标准，而非该列数据。在实际情况中，该列数据会被部分用户当成隐私数据，因此有必要对该列的隐私保护情况进行度量。 可以看出，消毒后的 Age 列与 ZIP Code 列呈现严格的一一对应的关系，即知道 ZIP Code 值后，可以直接定位到 Age，但这并不代表着数据被完全泄漏，因为该列数据进行了熵减处理，导致与原始数据有很大的差异，原始数据有 9 个不同的值，而消毒后仅仅有 2 个不同的值，每个值不再精确到个位，而是一个范围。使得隐私保护效果同样有很大的提高。

### 实验分析

本节详细介绍了模拟中使用的微数据库以及其中使用的确定性匿名化机制。我们还提供了有关其他实现方面的信息，包括属性分类和用于执行仿真的工具。

本章节使用一个大规模的数据集，在将其调整，满足各种数据的匿名模型后，度量其隐私保护效果。观测度量值与真实值的差异。

#### 数据集

数据集选用：成人数据集，最初是从1994年美国人口普查数据库中提取的。 它由15个数字和分类属性组成，共32561行。 但是，在删除包含丢失信息和删除在我们工作中没有特定作用的属性之后，我们选择了该数据集的一个子集。 成人数据集的最后子集有30162行和以下十个属性 - 索引，年龄，工作类型，教育程度，母国国籍，职业，种族，性别，薪资和婚姻状态。数据集的具体情况如下表：

|      | 类型     | 属性       | 不同值数量 | 符号     |
| ---- | -------- | ---------- | ---------- | -------- |
| 1    | 索引     | 识别符     | 30162      | $K_1$    |
| 2    | 年龄     | 准识别符   | 74         | $K_2$    |
| 3    | 工作类型 | 准识别符   | 8          | $K_3$    |
| 4    | 教育程度 | 敏感属性   | 16         | $K_4$    |
| 5    | 母国国籍 | 敏感属性   | 41         | $K_5$    |
| 6    | 职业     | 准识别符   | 14         | $K_6$    |
| 7    | 种族     | 准识别符   | 5          | $K_7$    |
| 8    | 性别     | 准识别符   | 2          | $K_8$    |
| 9    | 薪资     | 准识别符   | 2          | $K_9$    |
| 10   | 婚姻状况 | 准识别符   | 7          | $K_{10}$ |
| 11   | –        | 不敏感属性 | –          |          |

使用 ARX 软件对数据进行处理，该软件为开源的敏感数据匿名软件。在整个过程中，设置匿名的方式为泛化，分别使得数据或属性满足，k-anonymity、t-closeness、l-diversity。

#### 隐私度量结果

##### k-anonymity

其中选择 $k=\{2,3,4,5,6,7\}$ 进行实验。教育程度，母国国籍为隐私属性，索引为识别符，其余属性为准识别符。在发布时，将删除索引列，因此在计算时忽略该列的信息。

![image-20240325222426765](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20240325222426765.png)

由图 1 可以看出，随着 k 值的不断增加，整体的 PL 值与两个隐私属性的 PL 值都在不断减少，而在 k-anonymity 中，数据的隐私保护程度会随着 k 的增加而增加，完全符合 k 匿名的规则。同时，从图 2 可以看出，其余的属性虽然没有对其进行专门的隐私保护处理，但是在处理 k 匿名的过程中，这些准识别符数据也进行了一定程度的处理，导致信息熵发生了减少，以至于 PL 值虽然没有严格按照 k 的变化而变化，却都小于 1。

##### l-diversity

选择 $l=\{2,3,4,5,6,7\}$ 进行实验，且两个隐私属性教育程度与国籍都要满足 l-diversity。即一个准标识符至少要对应出 l 种不同的教育程度与国籍。

![image-20240325231121089](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20240325231121089.png)

从整体上看，两个隐私属性与整体的隐私保护程度都随着 l 的增加而增加。准标识符的隐私保护程度与 k-anonymity 类似也都小于1，但是并没有与 l 的值有着较大的关联。由于 l-diversity 相比 k-anonymity 对准表示符要有着更加严格的处理，即使 l 取最小值 2 时的隐私保护程度也大于图 1 中 k=16 时的隐私保护程度。

##### t-closeness

 $t=\{0.05, 0.1, 0.15, 0.2, 0.25, 0.3\}$ 两个属性的 $t$ 值相同，其隐私保护程度随着 $t$ 值的增加而减少。

![image-20240325232133139](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20240325232133139.png)

与前两个匿名方式不同，t-closeness的理论隐私保护程度随着 t 的增加而增加，因此最终得到的曲线是单调递增的。而图 6 中几条非隐私属性的 PL 曲线和前面两种匿名方式相比，有着更强的规律性，虽然并不是严格的单调递增曲线，但是可以很明显地看出都在波动中逐渐上升。在 t=0.05 时，PL 值达到极小，查看数据可以发现，大部分数据已经匿名到了最高层级。

通过观察 3 幅图，可以发现，无论是那种匿名方式，国籍属性的PL 值一直是最大的，整体的 PL 值居中，教育程度的 PL 值最小。这主要是由于原国籍属性有着更多种类的值，因此在进行匿名时，可以对准标识符进行更少的处理即可达到要求，处理更少，隐私保护程度相对也就较低。

|      | sex      | age      | race     | marital-status | occupation | workclass | salary-class | education | native-country | all      |
| ---- | -------- | -------- | -------- | -------------- | ---------- | --------- | ------------ | --------- | -------------- | -------- |
| 0    | 0.628091 | 0.230373 | 0.607267 | 0.637079       | 0.41098    | 0.590474  | 0.613028     | 0.51144   | 0.664766       | 0.58227  |
| 1    | 0.711248 | 0.263201 | 0.759853 | 0.717669       | 0.474725   | 0.638646  | 0.697758     | 0.414538  | 0.59468        | 0.497476 |
| 2    | 0.769291 | 0.267347 | 0.79993  | 0.753388       | 0.517626   | 0.719886  | 0.760494     | 0.350365  | 0.540316       | 0.438039 |
| 3    | 0.808412 | 0.270559 | 0.855679 | 0.783367       | 0.547122   | 0.737812  | 0.829492     | 0.302368  | 0.502145       | 0.392308 |
| 4    | 0.808412 | 0.270559 | 0.855679 | 0.783367       | 0.547122   | 0.737812  | 0.829492     | 0.302368  | 0.502145       | 0.392308 |
| 5    | 0.858834 | 0.263599 | 0.89219  | 0.822799       | 0.588133   | 0.675166  | 0.894747     | 0.237362  | 0.424177       | 0.323419 |
| 6    | 0.602572 | 0.276421 | 0.437896 | 0.509934       | 0.462856   | 0.471218  | 0.64014      | 0.224391  | 0.624438       | 0.35037  |
| 7    | 0.908758 | 0.266524 | 0.727579 | 0.800004       | 0.542127   | 0.636158  | 0.943683     | 0.214301  | 0.481536       | 0.317626 |
| 8    | 0.951794 | 0.273136 | 0.671337 | 0.798067       | 0.571573   | 0.548541  | 0.942236     | 0.189354  | 0.407967       | 0.282806 |
| 9    | 0.944674 | 0.258816 | 0.72246  | 0.758569       | 0.514888   | 0.602137  | 0.954763     | 0.163286  | 0.357655       | 0.250857 |
| 10   | 0.939641 | 0.245234 | 0.74582  | 0.745042       | 0.463126   | 0.565109  | 0.971752     | 0.145759  | 0.327748       | 0.229109 |
| 11   | 0.876195 | 0.247491 | 0.642717 | 0.727973       | 0.48503    | 0.44756   | 0.938298     | 0.128289  | 0.287939       | 0.206711 |
| 12   | 0.590956 | 0.039066 | 0.281942 | 0.282753       | 0.058635   | 0.141773  | 0.025752     | 0.003939  | 0.046895       | 0.022967 |
| 13   | 0.643388 | 0.222495 | 0.316703 | 0.471499       | 0.08598    | 0.295546  | 0.270478     | 0.020908  | 0.085323       | 0.059058 |
| 14   | 0.803643 | 0.254639 | 0.501137 | 0.516025       | 0.172526   | 0.566705  | 0.422015     | 0.040668  | 0.145867       | 0.096514 |
| 15   | 0.960129 | 0.259839 | 0.532904 | 0.746907       | 0.267163   | 0.490481  | 0.465355     | 0.069495  | 0.20193        | 0.138587 |
| 16   | 0.860692 | 0.268136 | 0.734936 | 0.675216       | 0.346114   | 0.592714  | 0.598151     | 0.094437  | 0.24635        | 0.165269 |
| 17   | 0.842999 | 0.270697 | 0.645244 | 0.78429        | 0.40072    | 0.611631  | 0.795196     | 0.140267  | 0.273701       | 0.210285 |

##### PL 值与效用

然而数据的消毒程度并不是越高越好，过高的消毒程度会使得数据的的信息量损失过大，使得数据的效用降低。然而效用的度量更加复杂，需要结合数据的用途来进行量化。不过，许多数据在发布时，并没有明确的用途，导致效用保留难以度量。

本文以数据处理前后信息熵的比值来表示数据的效用，和原始信息相比，处理后准标识符与隐私属性的信息熵越高，表明保存的数据越多，即数据在未来使用时，无论用它做什么，可获取到的信息量更多。本文所考虑的效用主要是数据的整体效用，单个属性的效用要结合实际情况考虑。

效用度量公式：
$$
UL(\overline{D})=\frac{H(\overline{X}_{pd})+H(\overline{X}_{prv})}{H({X}_{pd})+H({X}_{prv})}
$$


虽然不同的隐私模型往往有着不同的匿名标准，k，t，l 之间的值无法直接进行比较。但是在结合了效用值 UL 后，可以忽略隐私模型的不同，直接对其隐私与效用进行比较。

![image-20240326154446281](/Users/zangshuai/Library/Mobile Documents/com~apple~CloudDocs/笔记图片/image-20240326154446281.png)

在理论上，数据所达到的匿名程度越高，数据的隐私保护程度越高，数据的保留程度越小。但是，由于不同的匿名程度在实际处理时所采用的方法也会有差异，因此即使最终达到了相同的匿名程度，实际信息熵的保留程度也会有一定的不同。并不会按照理论上的保护程度发展。由上图可以看出，在总体趋势上，隐私保护程度与效用呈现负相关，不过仍有 3 个值由于匿名算法的原因导致整体曲线有较大的波动。

对隐私数据的处理方式也更加重要，防止出现隐私保护程度与效用保留程度同时很差的现象。

### 本章小结

在本文中，我们使用了信息论的度量方法，提出了一个相对通用的隐私度量框架，可用于度量数据匿名前后的隐私保护程度，从而保证将要发布的数据不会发生较严重的隐私泄漏。由于隐私水平的度量仅仅需要对比数据匿名前后的差异，并不需要知道整体的匿名化过程，因此在保证了度量方法更加通用的同时，也保证了方法的易用性。本文先使用了仅有 9 行数据的小的数据集来介绍度量方法，然后在实验部分使用了一个开源的数据集来验证，将这个开源数据集处理成满足 3 种不同隐私模型（k-anonymity[9]、t-closeness[10]、l-diversity[11]）的数据，并且每个隐私模型都选择了多种参数。最终以图表的形式，得出了参数与隐私保护程度的关系，确保度量结果与真实结果一致。

不过，本文所提出来的度量方法，还无法适用于对熵增数据的隐私度量。如通过给原始数据加噪声的方法进行数据的隐私保护，这个方法常用在差分隐私机制中。由于数据处理前后发生的变化会导致熵增，这会使得本文最终得到的结论发生错误。如果数据在处理前后的信息熵不变，如对仅对同一列的数据进行交换位置而不改变值，使用 PL 进行度量同样会发生错误。在未来的工作中，将会着重于对这两种处理方式下数据隐私的度量，最好能归纳出一个同时满足于熵增与熵减的度量方法。

## 总结与展望（1.5）

### 本文总结





### 未来展望

我们提出了AB-measure和Ob-measure算法，这是衡量给定SDP算法的度量保护程度的实用方法。OB测量算法更通用，可以测量常用的SDP算法。AB-measure可以通过定制不同的算法来获得更准确的结果。然而，本文的工作主要集中在度量均值估计机制和频率估计机制上。我们预计未来的工作将扩展到更多的自民党机制。

本文我们提出了一个相对通用的隐私度量框架，用于度量数据匿名前后的隐私保护程度，从而保证将要发布的数据不会发生较严重的隐私泄露。本文提出的隐私水平的度量仅仅需要对比数据匿名前后的差异，并不需要知道整体的匿名化过程，因此保证了方法的通用性。实验部分使用了一个开源的数据集对我们的方法进行验证。并得出了参数与隐私保护程度的关系，确保度量结果的真实性。目前，本文所提出的度量方法还无法适用于对熵增数据的隐私度量。在未来的工作中，我们将会着重于对熵增数据隐私的度量，归纳得出一个同时满足于熵增与熵减的度量方法。





## 参考文献（7）

面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述面向动态数据发布的差分隐私保护研究综述

## 致谢

时光荏苒，三年的硕士研究生生涯转瞬即逝。在完成这篇论文的同时，我深感一路走来的收获与成长，离不开许多人的支持和帮助。在此，谨以此篇致谢，向所有帮助过我的师长、家人、朋友以及同学们表达我最诚挚的感谢。

首先，我要特别感谢张吉老师、朱友文老师、薛乔老师。从论文选题到研究方法，再到最后的论文写作，您始终给予我耐心细致的指导。您的渊博学识和严谨治学的态度深深感染了我。在我迷茫时，您总是能以睿智的见解点明方向；在我遇到困难时，您给予了我莫大的支持和鼓励。没有您的悉心指导，我的论文以及学术能力都难以达到现在的水平。

同时，我还要感谢实验室的所有老师和同学。实验室提供了优越的科研环境和丰富的资源，帮助我完成了许多重要的实验工作。在研究过程中，实验室的老师们给予了我技术上的指导，同学们也与我分享了许多宝贵的经验。此外，感谢实验室的学长学姐们，您们对我研究思路的启发和论文写作的建议，为我的成长注入了强大的动力。

在此，我也要感谢我的家人，特别是我的父母。您们始终在我背后默默支持，为我提供了坚实的后盾。每当我面对压力时，您们的鼓励与关怀让我充满前进的动力。无论何时，您们始终是我努力的最大动力来源。我还要感谢在求学过程中结识的良师益友。特别感谢我的同学和好友叶克炉，在我的学习和生活中，您们带来了无数的欢声笑语，也给予了我诸多启发。每一次讨论、每一场交流，您们的建议和观点都让我受益匪浅。正是因为有您们的陪伴，这段求学时光才更加充实和有意义。

同时，我也感谢学校和学院提供的丰富学术资源和优质教育环境。感谢图书馆和各类科研平台，让我在论文写作和研究过程中能够获取前沿的信息和资料。这些资源为我奠定了坚实的学术基础。

最后，我要感谢所有直接或间接帮助过我的人。也许您们的名字未能在此一一列出，但您的关怀与支持，我都铭记于心。正是因为有您们的帮助，我才能克服重重困难，完成这篇论文。

这篇论文的完成是我三年研究生生活的总结，也是我人生中的一个重要里程碑。虽然毕业意味着一段旅程的结束，但同时也象征着新的起点。在未来的学习和工作中，我将铭记这段难忘的经历，并继续以严谨求实的态度面对新的挑战，努力为社会做出更多的贡献。

再次感谢所有帮助过我的人，谢谢！

## 在学期间的研究成果及发表的学术论文（1）









